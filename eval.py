import pandas as pd
import numpy as np
from datasets import load_dataset
from tqdm import tqdm
import nltk
from collections import Counter
from textstat import textstat
from bert_score import score as bert_score
from evaluate import load

nltk.download('punkt')

class DentalDatasetEvaluator:
    def __init__(self, dataset_name="NV9523/DentalGPT_SFT", sample_size=None):
        """
        Khá»Ÿi táº¡o bá»™ Ä‘Ã¡nh giÃ¡ dataset
        Args:
            dataset_name: TÃªn dataset trÃªn HuggingFace Hub
            sample_size: Sá»‘ lÆ°á»£ng máº«u cáº§n Ä‘Ã¡nh giÃ¡ (None Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ toÃ n bá»™)
        """
        self.dataset = self._load_dataset(dataset_name, sample_size)
        self.metrics = {
            'bleu': load("bleu"),
            'rouge': load("rouge"),
            'readability': textstat
        }
        self.results = {}

    def _load_dataset(self, dataset_name, sample_size):
        """Táº£i dataset vá»›i kÃ­ch thÆ°á»›c máº«u tuá»³ chá»n"""
        split = f"train[:{sample_size}]" if sample_size else "train"
        return load_dataset(dataset_name, split=split)

    def _calculate_text_metrics(self, text):
        """TÃ­nh cÃ¡c chá»‰ sá»‘ vá» Ä‘á»™ phá»©c táº¡p vÄƒn báº£n"""
        return {
            'word_count': len(nltk.word_tokenize(text)),
            'char_count': len(text),
            'sentence_count': len(nltk.sent_tokenize(text)),
            'flesch_reading_ease': self.metrics['readability'].flesch_reading_ease(text),
            'lexical_diversity': len(set(nltk.word_tokenize(text))) / len(nltk.word_tokenize(text))
        }

    def _analyze_content_distribution(self):
        """PhÃ¢n tÃ­ch phÃ¢n phá»‘i ná»™i dung trong dataset"""
        topics = [example['Chá»§ Ä‘á»'] for example in self.dataset]
        return dict(Counter(topics))

    def _evaluate_qa_consistency(self):
        """ÄÃ¡nh giÃ¡ tÃ­nh nháº¥t quÃ¡n giá»¯a cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i"""
        questions = [example['CÃ¢u há»i'] for example in self.dataset]
        answers = [example['CÃ¢u tráº£ lá»i'] for example in self.dataset]
        
        # TÃ­nh BERTScore cho QA consistency
        P, R, F1 = bert_score(answers, questions, lang="vi", verbose=False)
        return {
            'bert_score_f1': F1.mean().item(),
            'qa_length_ratio': np.mean([len(a)/len(q) for q, a in zip(questions, answers)])
        }

    def _evaluate_cot_components(self):
        """ÄÃ¡nh giÃ¡ cÃ¡c thÃ nh pháº§n Chain-of-Thought"""
        cot_metrics = {
            'goal_length': [],
            'reasoning_length': [],
            'justification_length': []
        }
        
        for example in self.dataset:
            cot_metrics['goal_length'].append(len(example['CoT_Goal'].split()))
            cot_metrics['reasoning_length'].append(len(example['CoT_Reasoning'].split()))
            cot_metrics['justification_length'].append(len(example['CoT_Justification'].split()))
        
        return {k: np.mean(v) for k, v in cot_metrics.items()}

    def generate_report(self):
        """Táº¡o bÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n"""
        print("ğŸ” Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ bá»™ dá»¯ liá»‡u DentalGPT...")
        
        # 1. PhÃ¢n tÃ­ch cÆ¡ báº£n
        self.results['basic_stats'] = {
            'dataset_size': len(self.dataset),
            'columns': list(self.dataset.features.keys())
        }

        # 2. PhÃ¢n tÃ­ch phÃ¢n phá»‘i ná»™i dung
        self.results['content_distribution'] = self._analyze_content_distribution()

        # 3. ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng vÄƒn báº£n
        print("\nğŸ“ Äang phÃ¢n tÃ­ch cháº¥t lÆ°á»£ng vÄƒn báº£n...")
        sample_text = self.dataset[0]['CÃ¢u tráº£ lá»i']
        self.results['text_quality'] = self._calculate_text_metrics(sample_text)

        # 4. ÄÃ¡nh giÃ¡ QA consistency
        print("\nğŸ”— Äang Ä‘Ã¡nh giÃ¡ tÃ­nh nháº¥t quÃ¡n QA...")
        self.results['qa_consistency'] = self._evaluate_qa_consistency()

        # 5. PhÃ¢n tÃ­ch thÃ nh pháº§n CoT
        print("\nğŸ§  Äang phÃ¢n tÃ­ch Chain-of-Thought...")
        self.results['cot_analysis'] = self._evaluate_cot_components()

        # Xuáº¥t bÃ¡o cÃ¡o
        self._print_report()

        return self.results

    def _print_report(self):
        """In bÃ¡o cÃ¡o Ä‘á»‹nh dáº¡ng Ä‘áº¹p"""
        print("\nğŸ“Š BÃO CÃO ÄÃNH GIÃ Bá»˜ Dá»® LIá»†U")
        print("="*60)
        
        # 1. ThÃ´ng tin cÆ¡ báº£n
        print(f"\nğŸ“Œ Tá»•ng sá»‘ máº«u: {self.results['basic_stats']['dataset_size']}")
        print(f"ğŸ“Œ CÃ¡c trÆ°á»ng dá»¯ liá»‡u: {', '.join(self.results['basic_stats']['columns'])}")
        
        # 2. PhÃ¢n phá»‘i chá»§ Ä‘á»
        print("\nğŸŒ PhÃ¢n phá»‘i chá»§ Ä‘á»:")
        for topic, count in self.results['content_distribution'].items():
            print(f"  - {topic}: {count} máº«u ({count/len(self.dataset)*100:.1f}%)")
        
        # 3. Cháº¥t lÆ°á»£ng vÄƒn báº£n
        print("\nğŸ“– Cháº¥t lÆ°á»£ng vÄƒn báº£n (vÃ­ dá»¥ máº«u):")
        print(f"  - Sá»‘ tá»«: {self.results['text_quality']['word_count']}")
        print(f"  - Äá»™ dÃ i cÃ¢u: {self.results['text_quality']['sentence_count']}")
        print(f"  - Äá»™ phá»©c táº¡p (Flesch): {self.results['text_quality']['flesch_reading_ease']:.1f}")
        print(f"  - Äa dáº¡ng tá»« vá»±ng: {self.results['text_quality']['lexical_diversity']:.2f}")
        
        # 4. QA Consistency
        print("\nğŸ”— Chá»‰ sá»‘ nháº¥t quÃ¡n QA:")
        print(f"  - BERTScore F1: {self.results['qa_consistency']['bert_score_f1']:.3f}")
        print(f"  - Tá»· lá»‡ Ä‘á»™ dÃ i tráº£ lá»i/cÃ¢u há»i: {self.results['qa_consistency']['qa_length_ratio']:.2f}")
        
        # 5. PhÃ¢n tÃ­ch CoT
        print("\nğŸ§  PhÃ¢n tÃ­ch Chain-of-Thought:")
        print(f"  - Äá»™ dÃ i trung bÃ¬nh má»¥c tiÃªu: {self.results['cot_analysis']['goal_length']:.1f} tá»«")
        print(f"  - Äá»™ dÃ i trung bÃ¬nh láº­p luáº­n: {self.results['cot_analysis']['reasoning_length']:.1f} tá»«")
        print(f"  - Äá»™ dÃ i trung bÃ¬nh giáº£i thÃ­ch: {self.results['cot_analysis']['justification_length']:.1f} tá»«")

if __name__ == "__main__":
    # Khá»Ÿi táº¡o vÃ  cháº¡y Ä‘Ã¡nh giÃ¡
    evaluator = DentalDatasetEvaluator(sample_size=100)
    report = evaluator.generate_report()