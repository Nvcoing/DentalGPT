from datasets import load_dataset, Dataset

def build_dataset(hf_repo: str = "NV9523/DentalGPT_SFT") -> Dataset:
    # Load dataset tá»« HuggingFace Hub
    ds = load_dataset(hf_repo, split="train")
    # Äá»•i tÃªn cá»™t theo chuáº©n
    ds = ds.rename_columns({
        "Instruction":"instruction",
        "CÃ¢u há»i": "question",
        "CoT_Goal": "goal",
        "CoT_Reasoning": "reasoning",
        "CoT_Justification": "justification",
        "CÃ¢u tráº£ lá»i": "answer",
        "label1":"format",
        "label2":"content",
        "label3":"specialized"
        
    })

    # Lá»c bá» cÃ¡c hÃ ng thiáº¿u thÃ´ng tin
    def is_valid(x):
        return all(x.get(k) for k in ['instruction','question', 'goal', 'reasoning', 'justification', 'answer',"format","content","specialized"])

    ds = ds.filter(is_valid)

    # HÃ m táº¡o prompt theo Ä‘á»‹nh dáº¡ng má»›i
    def create_prompt(batch):
        prompts = []
        for i,q, g, r, j, a, f, c, s in zip(batch['instruction'],batch['question'], batch['goal'], batch['reasoning'], batch['justification'], batch['answer'],batch['format'],batch['content'],batch['specialized']):
            prompt = (
                "<ï½œbeginâ–ofâ–sentenceï½œ>"
                "<ï½œsystemï½œ>\n"
                f"###HÆ°á»›ng dáº«n: {i.strip()}\n"
                "<ï½œuserï½œ>\n"
                f"###CÃ¢u há»i:\n {q.strip()}\n"
                "<ï½œthinkï½œ>\n"
                "HÃ£y cÃ¹ng diá»…n giáº£i tá»«ng bÆ°á»›c nÃ o!ğŸ¤”\n"
                "<reasoning_cot>\n"
                "# ğŸ§  Suy luáº­n cá»§a DentalGPT\n"
                f"## 1ï¸âƒ£ Má»¥c tiÃªu ğŸ“Œ\n{g.strip()}\n"
                f"## 2ï¸âƒ£ BÆ°á»›c suy nghÄ© âš™ï¸\n{r.strip()}\n"
                f"## 3ï¸âƒ£ Giáº£i thÃ­ch ğŸ“\n{j.strip()}\n"
                "</reasoning_cot>\n"
                "<ï½œexpertï½œ>\n"
                "<experting>\n"
                "# ğŸ‘¨â€ğŸ”¬ ChuyÃªn gia\n"
                f"##TrÃ¬nh bÃ y dáº¡ng: {f.strip()}\n"
                f"##Ná»™i dung vá»: {c.strip()}\n"
                f"##ChuyÃªn sÃ¢u vá»: {s.strip()}\n"
                "</experting>\n"
                "<ï½œassistantï½œ>\n"
                "<answer>\n"
                f"# ğŸ’¬ CÃ¢u tráº£ lá»i\n{a.strip()}\n"
                "</answer>"
                "<ï½œendâ–ofâ–sentenceï½œ>"
            )
            prompts.append(prompt)
        return {"text": prompts}

    # Táº¡o cá»™t 'text'
    ds = ds.map(create_prompt, batched=True, batch_size=64)

    # Chá»‰ giá»¯ láº¡i cá»™t 'text' trong dataset
    return ds.remove_columns([col for col in ds.column_names if col != "text"])
