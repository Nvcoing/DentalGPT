from datasets import load_dataset, Dataset
import pandas as pd

def build_dataset(hf_repo: str = "NV9523/DentalGPT_SFT"):
    # Load dataset tá»« HuggingFace Hub
    train_ds = load_dataset(hf_repo, split="train")
    eval_ds = load_dataset(hf_repo, split="validation")
    
    # Äá»•i tÃªn cá»™t theo chuáº©n
    def rename_columns(ds):
        ds = ds.rename_columns({
            "Instruction":"instruction",
            "CÃ¢u há»i": "question",
            "CoT_Goal": "goal",
            "CoT_Reasoning": "reasoning",
            "CoT_Justification": "justification",
            "CÃ¢u tráº£ lá»i": "answer",
            "label1":"format",
            "label2":"content",
            "label3":"specialized"
        })
        return ds
    
    # Lá»c bá» cÃ¡c hÃ ng thiáº¿u thÃ´ng tin
    def is_valid(x):
        return all(x.get(k) for k in ['instruction','question', 'goal', 'reasoning', 'justification', 'answer', "format", "content", "specialized"])
    
    # Process both datasets
    def process_dataset(ds):
        ds = rename_columns(ds)
        ds = ds.filter(is_valid)
        return ds
    
    train_ds = process_dataset(train_ds)
    eval_ds = process_dataset(eval_ds)
    
    # HÃ m táº¡o prompt theo Ä‘á»‹nh dáº¡ng má»›i
    def create_prompt(batch):
        prompts = []
        for i, q, g, r, j, a, f, c, s in zip(
            batch['instruction'], batch['question'], batch['goal'], 
            batch['reasoning'], batch['justification'], batch['answer'],
            batch['format'], batch['content'], batch['specialized']
        ):
            prompt = (
                "<ï½œbeginâ–ofâ–sentenceï½œ>"
                "<ï½œsystemï½œ>\n"
                f"### HÆ°á»›ng dáº«n: {i.strip()}\n"
                "<ï½œuserï½œ>\n"
                f"### CÃ¢u há»i:\n {q.strip()}\n"
                "<ï½œthinkï½œ>\n"
                "HÃ£y cÃ¹ng diá»…n giáº£i tá»«ng bÆ°á»›c nÃ o!ğŸ¤”\n"
                "<reasoning_cot>\n"
                "# ğŸ§  Suy luáº­n cá»§a DentalGPT\n"
                f"## 1ï¸âƒ£ Má»¥c tiÃªu ğŸ“Œ\n{g.strip()}\n"
                f"## 2ï¸âƒ£ BÆ°á»›c suy nghÄ© âš™ï¸\n{r.strip()}\n"
                f"## 3ï¸âƒ£ Giáº£i thÃ­ch ğŸ“\n{j.strip()}\n"
                "</reasoning_cot>\n"
                "<ï½œexpertï½œ>\n"
                "<experting>\n"
                "# ğŸ‘¨â€ğŸ”¬ ChuyÃªn gia\n"
                f"## TrÃ¬nh bÃ y dáº¡ng: {f.strip()}\n"
                f"## Ná»™i dung vá»: {c.strip()}\n"
                f"## ChuyÃªn sÃ¢u vá»: {s.strip()}\n"
                "</experting>\n"
                "<ï½œassistantï½œ>\n"
                "<answer>\n"
                f"# ğŸ’¬ CÃ¢u tráº£ lá»i\n{a.strip()}\n"
                "</answer>"
                "<ï½œendâ–ofâ–sentenceï½œ>"
            )
            prompts.append(prompt)
        return {"text": prompts}
    
    # Apply to both datasets
    train_ds = train_ds.map(create_prompt, batched=True, batch_size=1024)
    eval_ds = eval_ds.map(create_prompt, batched=True, batch_size=1024)
    
    return train_ds.remove_columns([col for col in train_ds.column_names if col != "text"]), \
           eval_ds.remove_columns([col for col in eval_ds.column_names if col != "text"])