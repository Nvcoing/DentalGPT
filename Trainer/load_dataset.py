from datasets import load_dataset, Dataset

def build_dataset(hf_repo: str = "NV9523/DentalGPT_SFT", filename: str = "Dental_CoT_dataset.parquet") -> Dataset:
    # Load dataset tá»« HuggingFace Hub
    ds = load_dataset(hf_repo, data_files=filename, split="train")

    # Äá»•i tÃªn cá»™t theo chuáº©n
    ds = ds.rename_columns({
        "CÃ¢u há»i": "question",
        "CoT_Goal": "goal",
        "CoT_Reasoning": "reasoning",
        "CoT_Justification": "justification",
        "CÃ¢u tráº£ lá»i": "answer"
    })

    # Lá»c bá» cÃ¡c hÃ ng thiáº¿u thÃ´ng tin
    def is_valid(x):
        return all(x.get(k) for k in ['question', 'goal', 'reasoning', 'justification', 'answer'])

    ds = ds.filter(is_valid)

    # HÃ m táº¡o prompt theo Ä‘á»‹nh dáº¡ng má»›i
    def create_prompt(batch):
        prompts = []
        for q, g, r, j, a in zip(batch['question'], batch['goal'], batch['reasoning'], batch['justification'], batch['answer']):
            prompt = (
                "<ï½œbeginâ–ofâ–sentenceï½œ>"
                "<ï½œuserï½œ>\n"
                f"###CÃ¢u há»i:\n {q.strip()}\n"
                "<|think|>\n"
                "HÃ£y cÃ¹ng diá»…n giáº£i tá»«ng bÆ°á»›c nÃ o!ğŸ¤”\n"
                "<reasoning_cot>\n"
                "# ğŸ§  Suy luáº­n cá»§a DentalGPT\n"
                f"## 1ï¸âƒ£ Má»¥c tiÃªu ğŸ“Œ\n{g.strip()}\n"
                f"## 2ï¸âƒ£ BÆ°á»›c suy nghÄ© âš™ï¸\n{r.strip()}\n"
                f"## 3ï¸âƒ£ Giáº£i thÃ­ch ğŸ“\n{j.strip()}\n"
                "</reasoning_cot>\n"
                "<|assistant|>\n"
                "<answer>\n"
                f"# ğŸ’¬ CÃ¢u tráº£ lá»i\n{a.strip()}\n"
                "</answer>"
                "<ï½œendâ–ofâ–sentenceï½œ>"
            )
            prompts.append(prompt)
        return {"text": prompts}

    # Táº¡o cá»™t 'text'
    ds = ds.map(create_prompt, batched=True, batch_size=64)

    # Chá»‰ giá»¯ láº¡i cá»™t 'text' trong dataset
    return ds.remove_columns([col for col in ds.column_names if col != "text"])
