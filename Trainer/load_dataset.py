from datasets import load_dataset, Dataset, DatasetDict
import pandas as pd

def build_dataset(hf_repo: str = "NV9523/DentalGPT_SFT"):
    # Load dataset tá»« HuggingFace Hub
    ds = load_dataset(hf_repo, split="train")
    
    # Chuyá»ƒn sang pandas DataFrame Ä‘á»ƒ xá»­ lÃ½
    df = ds.to_pandas()
    
    # Táº¡o eval dataset báº±ng cÃ¡ch láº¥y máº«u theo nhÃ³m
    eval_df = df.groupby(['label1', 'label2', 'label3']).head(10).reset_index(drop=True)
    
    # Loáº¡i bá» cÃ¡c máº«u eval tá»« train dataset
    train_df = df[~df.index.isin(eval_df.index)]
    
    # Äá»•i tÃªn cá»™t theo chuáº©n
    def rename_columns(df):
        return df.rename(columns={
            "Instruction": "instruction",
            "CÃ¢u há»i": "question",
            "CoT_Goal": "goal",
            "CoT_Reasoning": "reasoning",
            "CoT_Justification": "justification",
            "CÃ¢u tráº£ lá»i": "answer",
            "label1": "format",
            "label2": "content",
            "label3": "specialized"
        })
    
    train_df = rename_columns(train_df)
    eval_df = rename_columns(eval_df)
    
    # Lá»c bá» cÃ¡c hÃ ng thiáº¿u thÃ´ng tin
    def is_valid(row):
        return all(row.get(k) for k in ['instruction', 'question', 'goal', 
                                      'reasoning', 'justification', 'answer',
                                      'format', 'content', 'specialized'])
    
    train_df = train_df[train_df.apply(is_valid, axis=1)]
    eval_df = eval_df[eval_df.apply(is_valid, axis=1)]
    
    # Táº¡o prompt
    def create_prompt(row):
        return (
            "<|system|>\n"
            f"###HÆ°á»›ng dáº«n: {row['instruction'].strip()}\n"
            "<|user|>\n"
            f"###CÃ¢u há»i:\n {row['question'].strip()}\n"
            "<|think|>\n"
            "HÃ£y cÃ¹ng diá»…n giáº£i tá»«ng bÆ°á»›c nÃ o!ğŸ¤”\n"
            "<reasoning_cot>\n"
            "# ğŸ§  Suy luáº­n cá»§a DentalGPT\n"
            f"## 1ï¸âƒ£ Má»¥c tiÃªu ğŸ“Œ\n{row['goal'].strip()}\n"
            f"## 2ï¸âƒ£ BÆ°á»›c suy nghÄ© âš™ï¸\n{row['reasoning'].strip()}\n"
            f"## 3ï¸âƒ£ Giáº£i thÃ­ch ğŸ“\n{row['justification'].strip()}\n"
            "</reasoning_cot>\n"
            "<|expert|>\n"
            "<experting>\n"
            "# ğŸ‘¨â€ğŸ”¬ ChuyÃªn gia\n"
            f"##TrÃ¬nh bÃ y dáº¡ng: {row['format'].strip()}\n"
            f"##Ná»™i dung vá»: {row['content'].strip()}\n"
            f"##ChuyÃªn sÃ¢u vá»: {row['specialized'].strip()}\n"
            "</experting>\n"
            "<|assistant|>\n"
            "<answer>\n"
            f"# ğŸ’¬ CÃ¢u tráº£ lá»i\n{row['answer'].strip()}\n"
            "</answer>"
        )
    
    train_df['text'] = train_df.apply(create_prompt, axis=1)
    eval_df['text'] = eval_df.apply(create_prompt, axis=1)
    
    # Chuyá»ƒn láº¡i sang Dataset
    train_ds = Dataset.from_pandas(train_df[['text']])
    eval_ds = Dataset.from_pandas(eval_df[['text']])
    
    return train_ds, eval_ds