{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411b08ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triton'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextIteratorStreamer\n",
      "File \u001b[1;32md:\\AnacondaEnvs\\AI\\Lib\\site-packages\\unsloth\\__init__.py:141\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# For Gradio HF Spaces?\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# if \"SPACE_AUTHOR_NAME\" not in os.environ and \"SPACE_REPO_NAME\" not in os.environ:\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[0;32m    142\u001b[0m libcuda_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(triton\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'triton'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from transformers import TextIteratorStreamer\n",
    "import threading\n",
    "\n",
    "# C·∫•u h√¨nh\n",
    "max_seq_length = 512\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "     model_name=r\"D:\\Folder_HocTap\\ƒê·ªì √°n t·ªët nghi·ªáp\\Code\\Thesis_FineTune_MoE_ChatBotDental\\Model\\Model_demo_40K\\DentalGPT_demo_40k\",\n",
    "     max_seq_length=max_seq_length,\n",
    "     dtype=dtype,\n",
    "     load_in_4bit=load_in_4bit,\n",
    " )\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "system_prompt = (\n",
    "    \"H√£y l√† m·ªôt chuy√™n gia v·ªÅ nha khoa ƒë√£ c√≥ nhi·ªÅu nƒÉm kinh nghi·ªám v√† c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi m·ªôt c√°ch d·ªÖ hi·ªÉu \"\n",
    "    \"cho ng∆∞·ªùi Vi·ªát Nam t·ª´ chuy√™n s√¢u ƒë·∫øn ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu. H√£y tr·∫£ l·ªùi c√¢u h·ªèi d∆∞·ªõi ƒë√¢y m·ªôt c√°ch ƒë∆°n gi·∫£n, ƒë·∫ßy ƒë·ªß, \"\n",
    "    \"d·ªÖ hi·ªÉu, ƒë√∫ng tr·ªçng t√¢m v√† ƒë√∫ng ng·ªØ c·∫£nh b·∫±ng ti·∫øng Vi·ªát:\"\n",
    ")\n",
    "\n",
    "def build_prompt_cot(user_input, cot_goal, cot_reasoning, cot_justification):\n",
    "    return (\n",
    "        f\"<|user|>\\n{system_prompt}\\n\\n\"\n",
    "        f\"<|thought|>\\nC√¢u h·ªèi: {user_input}\\n\"\n",
    "        f\"M·ª•c ti√™u: {cot_goal}\\n\"\n",
    "        f\"B∆∞·ªõc: {cot_reasoning}\\n\"\n",
    "        f\"Suy lu·∫≠n: {cot_justification}\\n\"\n",
    "    )\n",
    "\n",
    "def process_stream(stream_text):\n",
    "    if \"<|assistant|>\" in stream_text:\n",
    "        assistant_part = stream_text.split(\"<|assistant|>\")[1].strip()\n",
    "        if assistant_part.lower().startswith(\"c√¢u tr·∫£ l·ªùi:\"):\n",
    "            assistant_part = assistant_part[len(\"c√¢u tr·∫£ l·ªùi:\"):].strip()\n",
    "        return assistant_part\n",
    "    return None\n",
    "\n",
    "def chatbot_stream(user_input, cot_goal, cot_reasoning, cot_justification):\n",
    "    prompt = build_prompt_cot(user_input, cot_goal, cot_reasoning, cot_justification)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "    generation_kwargs = dict(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "        top_p=0.85,\n",
    "        repetition_penalty=1.25,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    thread = threading.Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "\n",
    "    partial_text = \"\"\n",
    "    assistant_response = \"\"\n",
    "    for new_text in streamer:\n",
    "        partial_text += new_text\n",
    "        processed = process_stream(partial_text)\n",
    "        if processed is not None:\n",
    "            assistant_response = processed\n",
    "            yield partial_text, assistant_response\n",
    "        else:\n",
    "            yield partial_text, \"\"\n",
    "\n",
    "# ---------------- GIAO DI·ªÜN GRADIO -------------------\n",
    "with gr.Blocks(\n",
    "    css=\"\"\"\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
    "    * { font-family: 'Inter', sans-serif; }\n",
    "    body {\n",
    "        background-color: #f5f7fa;\n",
    "    }\n",
    "    .chatbot-box {\n",
    "        border-radius: 18px;\n",
    "        overflow: hidden;\n",
    "        box-shadow: 0 4px 20px rgba(0,0,0,0.1);\n",
    "    }\n",
    "    .user-message {\n",
    "        background: linear-gradient(135deg, #4f46e5, #8b5cf6);\n",
    "        color: white;\n",
    "        border-radius: 18px 18px 4px 18px;\n",
    "        padding: 12px;\n",
    "    }\n",
    "    .bot-message {\n",
    "        background-color: white;\n",
    "        border-radius: 18px 18px 18px 4px;\n",
    "        padding: 12px;\n",
    "        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
    "    }\n",
    "    .send-btn {\n",
    "        background: linear-gradient(135deg, #4f46e5, #8b5cf6);\n",
    "        color: white;\n",
    "        border-radius: 9999px;\n",
    "        padding: 8px 16px;\n",
    "        font-weight: 600;\n",
    "        transition: transform 0.2s ease;\n",
    "    }\n",
    "    .send-btn:hover {\n",
    "        transform: scale(1.05);\n",
    "    }\n",
    "    \"\"\"\n",
    ") as demo:\n",
    "\n",
    "    gr.HTML(\"\"\"\n",
    "    <header class=\"bg-white shadow-sm py-4 px-6 rounded-lg mb-4 flex items-center justify-between\">\n",
    "        <div class=\"flex items-center space-x-3\">\n",
    "            <div class=\"tooth-icon bg-indigo-600 w-10 h-10 rounded-lg flex items-center justify-center text-white\">\n",
    "                <i class=\"fas fa-tooth\"></i>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h1 class=\"text-xl font-bold text-gray-800\">DentalGPT</h1>\n",
    "                <p class=\"text-xs text-gray-500\">Tr·ª£ l√Ω Nha khoa Th√¥ng minh</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    </header>\n",
    "    \"\"\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"\", show_copy_button=True, elem_classes=\"chatbot-box\", height=500)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            user_input = gr.Textbox(label=\"\", placeholder=\"Nh·∫≠p c√¢u h·ªèi nha khoa t·∫°i ƒë√¢y...\", lines=3)\n",
    "        with gr.Column(scale=1):\n",
    "            submit_btn = gr.Button(\"G·ª≠i üöÄ\", elem_classes=\"send-btn\")\n",
    "\n",
    "    cot_goal = gr.Textbox(visible=False)\n",
    "    cot_reasoning = gr.Textbox(visible=False)\n",
    "    cot_justification = gr.Textbox(visible=False)\n",
    "\n",
    "    with gr.Accordion(\"üß† Chi ti·∫øt suy lu·∫≠n c·ªßa AI\", open=False):\n",
    "        reasoning_output = gr.Textbox(label=\"Lu·ªìng suy lu·∫≠n\", lines=8, interactive=False)\n",
    "        final_output = gr.Textbox(label=\"K·∫øt qu·∫£ cu·ªëi c√πng\", lines=6, interactive=False)\n",
    "\n",
    "    def respond(user_input, cot_goal, cot_reasoning, cot_justification, history):\n",
    "        partial, answer = \"\", \"\"\n",
    "        for partial, answer in chatbot_stream(user_input, cot_goal, cot_reasoning, cot_justification):\n",
    "            yield history + [(user_input, answer)], partial, answer\n",
    "\n",
    "    submit_btn.click(\n",
    "        respond,\n",
    "        inputs=[user_input, cot_goal, cot_reasoning, cot_justification, chatbot],\n",
    "        outputs=[chatbot, reasoning_output, final_output]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c03f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h2ogpte==1.6.27\n",
    "sk-fghVzpccmHmCu4hM1stYXP3LM1nzggIQCziKW4FiYjCE2gkU # m·ªôt b·ªô\n",
    "sk-GrUWAITYvE3nQ1d1ANrKF7mJ9GDSsKYOif4AfvYFA53MIbED # to√†n b·ªô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75252c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided document text, there is no specific information regarding the percentage of MCA (Middle Cerebral Artery) occlusion that leads to hemiplegia (li·ªát n·ª≠a ng∆∞·ªùi). The document primarily contains data related to a dental dataset, including questions, goals, reasoning, justifications, and answers related to dental research. Therefore, the requested information about MCA occlusion and hemiplegia is not available in the given context.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DocumentInfo(id='f46fbb85-c2a8-45d3-8be6-f1d14015b624', username='caovu9523@gmail.com', name='Dental_CoT_dataset.pdf', type='PDF', size=20896, page_count=1, guardrails_settings=None, connector='Upload', uri=None, original_type='Excel', meta_data_dict={'ocr_model': 'Automatic'}, status='completed', updated_at=datetime.datetime(2025, 4, 25, 7, 40, 15, 123214, tzinfo=TzInfo(UTC)), user_source_file=None, page_ocr_model_dict=None, page_layout_dict=None)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "\n",
    "client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key='sk-fghVzpccmHmCu4hM1stYXP3LM1nzggIQCziKW4FiYjCE2gkU',\n",
    ")\n",
    "\n",
    "# Automatically connects to the collection from the\n",
    "# collection-specific API key\n",
    "chat_session_id = client.create_chat_session_on_default_collection()\n",
    "\n",
    "# Query the collection\n",
    "with client.connect(chat_session_id) as session:\n",
    "    reply = session.query(\n",
    "        \"\"\"Tri·ªáu ch·ª©ng li·ªát n·ª≠a ng∆∞·ªùi th√¨ t·∫Øc MCA bao nhi√™u %\"\"\",\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "# Summarize each document\n",
    "default_collection = client.get_default_collection()\n",
    "documents = client.list_documents_in_collection(default_collection.id, offset=0, limit=99)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the information provided in the documents, there is no relevant data or context related to \"K·∫æT QU·∫¢ ƒêI·ªÄU TR·ªä PH·∫®U THU·∫¨T M·ªû S·ªå GI·∫¢I √âP B·ªÜNH NH]NNH·ªíI M√ÅU N^O DO T·∫ÆC ƒê·ªòNG M·∫†CH NhOT·∫†I B·ªÜNH VI·ªÜN ƒê·∫†I H·ªåC Y H[ N·ªòI.\" The documents only contain information about David Brent not signing a contract with Initech and the shipment of paper clips to Scranton and Filmer by Dunder Mifflin.\n",
      "According to the document titled \"IniTech.pdf (516ef04d-c967-4e18-938c-4a8490565224),\" David Brent did not sign any contract with Initech.\n",
      "According to the document titled \"IniTech.pdf (516ef04d-c967-4e18-938c-4a8490565224),\" David Brent did not sign any contract with Initech.\n",
      "{\"count\": 2}\n",
      "According to the information provided in the documents and images, 22 paper clips were shipped to Scranton.\n",
      "A total of 55 paper clips were shipped, with 22 sent to Scranton and 33 to Filmer.\n",
      "David Brent did not sign a contract with Initech.\n",
      "Drinking water is essential for maintaining good health and overall well-being. Here are several reasons why staying hydrated is beneficial:\n",
      "\n",
      "1. **Maintains Bodily Functions**: Water is crucial for various bodily functions, including digestion, absorption, circulation, and temperature regulation. It helps transport nutrients and oxygen to cells and removes waste products from the body.\n",
      "\n",
      "2. **Supports Digestion**: Adequate water intake aids in the digestion process by helping to break down food and absorb nutrients. It also prevents constipation by softening stools and promoting regular bowel movements.\n",
      "\n",
      "3. **Regulates Body Temperature**: Water helps regulate body temperature through sweating and respiration. Proper hydration ensures that the body can efficiently cool itself down when necessary.\n",
      "\n",
      "4. **Lubricates Joints**: Water acts as a lubricant for joints, reducing friction and allowing for smooth movement. This is particularly important for preventing joint pain and maintaining flexibility.\n",
      "\n",
      "5. **Protects Tissues and Organs**: Staying hydrated helps protect sensitive tissues and organs, including the eyes, mouth, and nose, by keeping them moist. It also cushions the brain, spinal cord, and other vital organs.\n",
      "\n",
      "6. **Boosts Skin Health**: Proper hydration can improve skin elasticity and appearance, reducing the risk of dryness and promoting a healthy, glowing complexion.\n",
      "\n",
      "7. **Enhances Physical Performance**: Dehydration can lead to fatigue, reduced endurance, and impaired physical performance. Drinking enough water helps maintain energy levels and supports optimal physical activity.\n",
      "\n",
      "8. **Supports Kidney Function**: Water is essential for kidney function, as it helps filter waste products from the blood and excrete them through urine. Adequate hydration reduces the risk of kidney stones and urinary tract infections.\n",
      "\n",
      "9. **Aids in Weight Management**: Drinking water can help with weight management by promoting a feeling of fullness and reducing the likelihood of overeating. It can also replace high-calorie, sugary beverages, contributing to a healthier diet.\n",
      "\n",
      "10. **Improves Cognitive Function**: Dehydration can negatively impact cognitive functions such as concentration, alertness, and short-term memory. Staying hydrated supports brain function and mental clarity.\n",
      "\n",
      "Overall, drinking water is vital for maintaining health and preventing various health issues. It is recommended to drink an adequate amount of water daily, which can vary depending on factors such as age, gender, activity level, and climate.\n"
     ]
    }
   ],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "\n",
    "client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key='sk-GrUWAITYvE3nQ1d1ANrKF7mJ9GDSsKYOif4AfvYFA53MIbED',\n",
    ")\n",
    "\n",
    "# Create a new collection\n",
    "collection_id = client.create_collection(\n",
    "    name='927fd1bf-e41b-46b4-b91c-a98337d32436',\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create documents\n",
    "# Note: Done for demonstration purposes only (not usually needed)\n",
    "with open('dunder_mifflin.txt', 'w') as f:\n",
    "    f.write('There were 55 paper clips shipped, 22 to Scranton and 33 to Filmer.')\n",
    "\n",
    "with open('initech.txt', 'w') as f:\n",
    "    f.write('David Brent did not sign any contract with Initech.')\n",
    "\n",
    "# Upload documents\n",
    "# Many file types are supported: text/image/audio documents and archives\n",
    "with open('dunder_mifflin.txt', 'rb') as f:\n",
    "    dunder_mifflin = client.upload('Dunder Mifflin.txt', f)\n",
    "\n",
    "with open('initech.txt', 'rb') as f:\n",
    "    initech = client.upload('IniTech.txt', f)\n",
    "\n",
    "# Ingest documents (Creates previews, chunks and embeddings)\n",
    "client.ingest_uploads(collection_id, [dunder_mifflin, initech])\n",
    "\n",
    "# Create a chat session\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "\n",
    "# Query the collection\n",
    "with client.connect(chat_session_id) as session:\n",
    "    reply = session.query(\n",
    "        'How many paper clips were shipped to Scranton?',\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "    reply = session.query(\n",
    "        'Did David Brent co-sign the contract with Initech?',\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "    # In case have multiple LLMs, route to LLM with best\n",
    "    # price/performance below given max cost\n",
    "    reply = session.query(\n",
    "        'Did David Brent co-sign the contract with Initech?',\n",
    "        llm='auto',\n",
    "        llm_args=dict(cost_controls=dict(max_cost=1e-2)),\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "    # Classification\n",
    "    reply = session.query(\n",
    "        'Did David Brent co-sign the contract with Initech?',\n",
    "        llm_args=dict(\n",
    "            guided_choice=['yes', 'no', 'unclear'],\n",
    "        ),\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "    # Create custom JSON\n",
    "    reply = session.query(\n",
    "        'How many paper clips were shipped to Scranton?',\n",
    "        llm_args=dict(\n",
    "            response_format='json_object',\n",
    "            guided_json={\n",
    "                '$schema': 'http://json-schema.org/draft-07/schema#',\n",
    "                'type': 'object',\n",
    "                'properties': {'count': {'type': 'integer'}},\n",
    "                'required': [\n",
    "                    'count',\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "    # Force multimodal vision mode (requires vision-capable LLMs)\n",
    "    reply = session.query(\n",
    "        'How many paper clips were shipped to Scranton?',\n",
    "        llm_args=dict(\n",
    "            enable_vision='on',\n",
    "        ),\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)\n",
    "\n",
    "# Summarize each document\n",
    "documents = client.list_documents_in_collection(collection_id, offset=0, limit=99)\n",
    "for doc in documents:\n",
    "    summary = client.process_document(\n",
    "        document_id=doc.id,\n",
    "        pre_prompt_summary='Pay attention to the following text in order to summarize.',\n",
    "        prompt_summary='Write a concise summary from the text above.',\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(summary.content)\n",
    "\n",
    "# Chat with LLM without a collection\n",
    "chat_session_id = client.create_chat_session()\n",
    "\n",
    "with client.connect(chat_session_id) as session:\n",
    "    reply = session.query(\n",
    "        'Why is drinking water good for you?',\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a11313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "\n",
    "client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key='sk-GrUWAITYvE3nQ1d1ANrKF7mJ9GDSsKYOif4AfvYFA53MIbED',\n",
    ")\n",
    "\n",
    "# Create a new collection\n",
    "collection_id = client.create_collection(\n",
    "    name='927fd1bf-e41b-46b4-b91c-a98337d32436',\n",
    "    description='',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b4e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chen B, Sun Y, Wei Z, et al c√≥ th·ªÉ l√† c√°c t√°c gi·∫£ c·ªßa m·ªôt b√†i b√°o khoa h·ªçc ho·∫∑c nghi√™n c·ª©u n√†o ƒë√≥. Trong c√°c t√†i li·ªáu khoa h·ªçc, t√™n c·ªßa c√°c t√°c gi·∫£ th∆∞·ªùng ƒë∆∞·ª£c li·ªát k√™ theo th·ª© t·ª± ƒë√≥ng g√≥p c·ªßa h·ªç v√†o c√¥ng tr√¨nh nghi√™n c·ª©u. ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt v·ªÅ nh·ªØng ng∆∞·ªùi n√†y v√† c√¥ng tr√¨nh nghi√™n c·ª©u c·ª• th·ªÉ m√† h·ªç ƒë√£ th·ª±c hi·ªán, b·∫°n c·∫ßn cung c·∫•p th√™m th√¥ng tin v·ªÅ ng·ªØ c·∫£nh ho·∫∑c ti√™u ƒë·ªÅ c·ªßa b√†i b√°o, nghi√™n c·ª©u ho·∫∑c lƒ©nh v·ª±c m√† h·ªç ƒëang l√†m vi·ªác.\n"
     ]
    }
   ],
   "source": [
    "# Create a chat session\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "\n",
    "# Query the collection\n",
    "with client.connect(chat_session_id) as session:\n",
    "    reply = session.query(\n",
    "        'Tri·ªáu ch·ª©ng li·ªát n·ª≠a ng∆∞·ªùi th√¨ t·∫Øc MCA bao nhi√™u %',\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eecd4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = client.list_documents_in_collection(collection_id, offset=0, limit=99)\n",
    "for doc in documents:\n",
    "    summary = client.process_document(\n",
    "        document_id=doc.id,\n",
    "        pre_prompt_summary='Tri·ªáu ch·ª©ng li·ªát n·ª≠a ng∆∞·ªùi th√¨ t·∫Øc MCA bao nhi√™u %',\n",
    "        prompt_summary='Tri·ªáu ch·ª©ng li·ªát n·ª≠a ng∆∞·ªùi th√¨ t·∫Øc MCA bao nhi√™u %',\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(summary.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
