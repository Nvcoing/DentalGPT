import requests
import time
import json
from gemini_tool.call_gemini import call_gemini
from config import NGROK_URL

# Template máº«u cho 3 loáº¡i bÃ¡o cÃ¡o nha khoa
TEMPLATES = {
    "report": {
        "name": "BÃ¡o cÃ¡o KhÃ¡m Nha khoa",
        "sections": [
            {
                "title": "ThÃ´ng tin bá»‡nh nhÃ¢n",
                "description": "ThÃ´ng tin cÃ¡ nhÃ¢n, tiá»n sá»­ bá»‡nh, lÃ½ do khÃ¡m"
            },
            {
                "title": "KhÃ¡m lÃ¢m sÃ ng",
                "description": "Triá»‡u chá»©ng, dáº¥u hiá»‡u lÃ¢m sÃ ng, tÃ¬nh tráº¡ng rÄƒng miá»‡ng"
            },
            {
                "title": "Cháº©n Ä‘oÃ¡n",
                "description": "Cháº©n Ä‘oÃ¡n sÆ¡ bá»™ vÃ  phÃ¢n biá»‡t cháº©n Ä‘oÃ¡n"
            },
            {
                "title": "Káº¿ hoáº¡ch Ä‘iá»u trá»‹",
                "description": "PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹, lá»i khuyÃªn, theo dÃµi"
            },
            {
                "title": "TiÃªn lÆ°á»£ng vÃ  hÆ°á»›ng dáº«n",
                "description": "TiÃªn lÆ°á»£ng bá»‡nh, hÆ°á»›ng dáº«n chÄƒm sÃ³c táº¡i nhÃ "
            }
        ]
    },
    "thesis": {
        "name": "Luáº­n vÄƒn/Äá»“ Ã¡n Nha khoa",
        "sections": [
            {
                "title": "Äáº·t váº¥n Ä‘á»",
                "description": "LÃ½ do chá»n Ä‘á» tÃ i, tÃ­nh cáº¥p thiáº¿t, má»¥c tiÃªu nghiÃªn cá»©u"
            },
            {
                "title": "Tá»•ng quan tÃ i liá»‡u",
                "description": "CÆ¡ sá»Ÿ lÃ½ thuyáº¿t, nghiÃªn cá»©u liÃªn quan, khoáº£ng trá»‘ng kiáº¿n thá»©c"
            },
            {
                "title": "Äá»‘i tÆ°á»£ng vÃ  phÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u",
                "description": "Thiáº¿t káº¿ nghiÃªn cá»©u, Ä‘á»‘i tÆ°á»£ng, tiÃªu chÃ­, phÆ°Æ¡ng phÃ¡p thu tháº­p dá»¯ liá»‡u"
            },
            {
                "title": "Káº¿t quáº£ nghiÃªn cá»©u",
                "description": "TrÃ¬nh bÃ y káº¿t quáº£, phÃ¢n tÃ­ch sá»‘ liá»‡u, biá»ƒu Ä‘á»“, báº£ng"
            },
            {
                "title": "Tháº£o luáº­n",
                "description": "Giáº£i thÃ­ch káº¿t quáº£, so sÃ¡nh vá»›i nghiÃªn cá»©u khÃ¡c, háº¡n cháº¿"
            },
            {
                "title": "Káº¿t luáº­n vÃ  kiáº¿n nghá»‹",
                "description": "TÃ³m táº¯t káº¿t quáº£ chÃ­nh, Ã½ nghÄ©a thá»±c tiá»…n, hÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo"
            }
        ]
    },
    "paper": {
        "name": "BÃ i bÃ¡o khoa há»c Nha khoa",
        "sections": [
            {
                "title": "TÃ³m táº¯t (Abstract)",
                "description": "TÃ³m táº¯t má»¥c tiÃªu, phÆ°Æ¡ng phÃ¡p, káº¿t quáº£ chÃ­nh, káº¿t luáº­n"
            },
            {
                "title": "Giá»›i thiá»‡u (Introduction)",
                "description": "Bá»‘i cáº£nh, váº¥n Ä‘á» nghiÃªn cá»©u, má»¥c tiÃªu, giáº£ thuyáº¿t"
            },
            {
                "title": "Váº­t liá»‡u vÃ  phÆ°Æ¡ng phÃ¡p (Materials & Methods)",
                "description": "Thiáº¿t káº¿ nghiÃªn cá»©u, Ä‘á»‘i tÆ°á»£ng, quy trÃ¬nh, phÃ¢n tÃ­ch thá»‘ng kÃª"
            },
            {
                "title": "Káº¿t quáº£ (Results)",
                "description": "TrÃ¬nh bÃ y káº¿t quáº£ khÃ¡ch quan, sá»‘ liá»‡u, hÃ¬nh áº£nh"
            },
            {
                "title": "Tháº£o luáº­n (Discussion)",
                "description": "Giáº£i thÃ­ch káº¿t quáº£, so sÃ¡nh nghiÃªn cá»©u, Ã½ nghÄ©a lÃ¢m sÃ ng"
            },
            {
                "title": "Káº¿t luáº­n (Conclusion)",
                "description": "TÃ³m táº¯t phÃ¡t hiá»‡n chÃ­nh, á»©ng dá»¥ng thá»±c tiá»…n, háº¡n cháº¿"
            }
        ]
    }
}

def build_prompt(question: str) -> str:
    """XÃ¢y dá»±ng prompt cÆ¡ báº£n cho LLM"""
    return (
        "<ï½œbeginâ–ofâ–sentenceï½œ>"
        "<ï½œsystemï½œ>\n"
        "### HÆ°á»›ng dáº«n: HÃ£y lÃ  lÃ  má»™t trá»£ lÃ½ áº£o nha khoa vÃ  tráº£ lá»i cÃ¢u há»i dÆ°á»›i Ä‘Ã¢y:\n"
        "<ï½œuserï½œ>\n"
        f"### CÃ¢u há»i:\n{question.strip()}\n"
        # "<ï½œthinkï½œ>\n"
        # "HÃ£y cÃ¹ng diá»…n giáº£i tá»«ng bÆ°á»›c nÃ o!ğŸ¤”\n"
        # "<reasoning_cot>\n"
        # "# ğŸ§  Suy luáº­n cá»§a DentalGPT\n"
        # f"## 1ï¸âƒ£ Má»¥c tiÃªu ğŸ“Œ\nTráº£ lá»i Ä‘Æ¡n giáº£n, Ä‘Ãºng trá»ng tÃ¢m, ngáº¯n gá»n, dá»… hiá»ƒu\n"
        # f"## 2ï¸âƒ£ BÆ°á»›c suy nghÄ© âš™ï¸\nBÆ°á»›c 1: XÃ¡c Ä‘á»‹nh Ä‘Ãºng cÃ¢u há»i\nBÆ°á»›c 2: XÃ¡c Ä‘á»‹nh cÃ¢u tráº£ lá»i\nBÆ°á»›c 3: XÃ¡c Ä‘á»‹nh cÃ¡ch trÃ¬nh bÃ y\n"
        # f"## 3ï¸âƒ£ Giáº£i thÃ­ch ğŸ“\nGiáº£i thÃ­ch ngáº¯n gá»n\n"
        # "</reasoning_cot>\n"
    )

def send_request(prompt: str, generation_params: dict):
    """Gá»­i prompt tá»›i server LLM"""
    try:
        response = requests.post(NGROK_URL, json={"prompt": prompt, **generation_params}, stream=True)
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        return f"Error during generation: {str(e)}"

def parse_llm_response(raw_response: str) -> str:
    """Parse response tá»« LLM Ä‘á»ƒ láº¥y pháº§n <answer>"""
    try:
        # TÃ¬m pháº§n <answer>
        start_tag = "<answer>"
        end_tag = "</answer>"
        
        start_idx = raw_response.find(start_tag)
        end_idx = raw_response.find(end_tag)
        
        if start_idx != -1 and end_idx != -1:
            # Láº¥y ná»™i dung giá»¯a <answer> vÃ  </answer>
            content = raw_response[start_idx + len(start_tag):end_idx].strip()
            return content
        else:
            # Náº¿u khÃ´ng tÃ¬m tháº¥y tag, tráº£ vá» toÃ n bá»™ response
            return raw_response.strip()
    except Exception as e:
        return raw_response.strip()

def detect_template_type(prompt: str) -> str:
    """XÃ¡c Ä‘á»‹nh loáº¡i bÃ¡o cÃ¡o tá»« ná»™i dung Ä‘áº§u vÃ o"""
    prompt_lower = prompt.lower()
    if any(kw in prompt_lower for kw in ["bÃ¡o cÃ¡o", "há»“ sÆ¡", "phiáº¿u khÃ¡m", "bá»‡nh Ã¡n", "khÃ¡m bá»‡nh"]):
        return "report"
    elif any(kw in prompt_lower for kw in ["luáº­n vÄƒn", "luáº­n Ã¡n", "thesis", "Ä‘á» tÃ i", "Ä‘á»“ Ã¡n"]):
        return "thesis"
    elif any(kw in prompt_lower for kw in ["paper", "bÃ i bÃ¡o", "nghiÃªn cá»©u khoa há»c", "journal"]):
        return "paper"
    return "report"  # Máº·c Ä‘á»‹nh

def generate_section_questions(user_prompt: str, section_title: str, section_description: str, template_type: str) -> str:
    """Sá»­ dá»¥ng Gemini Ä‘á»ƒ táº¡o cÃ¢u há»i chi tiáº¿t cho tá»«ng má»¥c"""
    
    gemini_prompt = f"""
Báº¡n lÃ  chuyÃªn gia nha khoa cÃ³ kinh nghiá»‡m. TÃ´i Ä‘ang viáº¿t má»™t {TEMPLATES[template_type]['name']}.

YÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng: "{user_prompt}"

Má»¥c hiá»‡n táº¡i: "{section_title}"
MÃ´ táº£ má»¥c: "{section_description}"

HÃ£y táº¡o ra 3-5 cÃ¢u há»i chi tiáº¿t vÃ  cá»¥ thá»ƒ Ä‘á»ƒ hÆ°á»›ng dáº«n viáº¿t ná»™i dung cho má»¥c nÃ y. 
CÃ¡c cÃ¢u há»i cáº§n:
1. PhÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng
2. Táº­p trung vÃ o má»¥c "{section_title}" 
3. CÃ³ tÃ­nh chuyÃªn mÃ´n cao trong lÄ©nh vá»±c nha khoa
4. GiÃºp táº¡o ra ná»™i dung cháº¥t lÆ°á»£ng vÃ  Ä‘áº§y Ä‘á»§

Chá»‰ tráº£ vá» danh sÃ¡ch cÃ¢u há»i, má»—i cÃ¢u há»i trÃªn má»™t dÃ²ng báº¯t Ä‘áº§u báº±ng "- ".
"""
    
    try:
        questions = call_gemini(gemini_prompt, model_name="models/gemini-1.5-flash-latest")
        return questions.strip()
    except Exception as e:
        # Fallback questions náº¿u Gemini lá»—i
        return f"- HÃ£y mÃ´ táº£ chi tiáº¿t vá» {section_title} trong bá»‘i cáº£nh: {user_prompt}"

def format_output_section(section_title: str, questions: str, content: str) -> str:
    """Format output cho tá»«ng má»¥c"""
    return f"""
## {section_title}

### CÃ¢u há»i hÆ°á»›ng dáº«n:
{questions}

### Ná»™i dung:
{content}

---
"""

def create_final_report_with_gemini(template_name: str, user_prompt: str, results: dict) -> str:
    """Sá»­ dá»¥ng Gemini Ä‘á»ƒ tá»•ng há»£p template thÃ nh bÃ¡o cÃ¡o cuá»‘i cÃ¹ng"""
    
    # Chuáº©n bá»‹ ná»™i dung Ä‘á»ƒ gá»­i cho Gemini
    sections_content = ""
    for section_title, data in results.items():
        sections_content += f"**{section_title}:**\n{data['content']}\n\n"
    
    gemini_prompt = f"""
Báº¡n lÃ  chuyÃªn gia nha khoa cÃ³ kinh nghiá»‡m. TÃ´i cÃ³ má»™t {template_name} vá»›i cÃ¡c má»¥c Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh nhÆ° sau:

**YÃªu cáº§u ban Ä‘áº§u:** {user_prompt}

**Ná»™i dung cÃ¡c má»¥c:**
{sections_content}

Nhiá»‡m vá»¥ cá»§a báº¡n:
1. Tá»•ng há»£p toÃ n bá»™ ná»™i dung thÃ nh má»™t bÃ¡o cÃ¡o hoÃ n chá»‰nh, máº¡ch láº¡c
2. Äáº£m báº£o tÃ­nh liÃªn káº¿t giá»¯a cÃ¡c má»¥c
3. Bá»• sung thÃªm thÃ´ng tin cáº§n thiáº¿t náº¿u cÃ³
4. Sá»­a lá»—i chÃ­nh táº£, ngá»¯ phÃ¡p náº¿u cÃ³
5. Äá»‹nh dáº¡ng láº¡i cho chuyÃªn nghiá»‡p vÃ  dá»… Ä‘á»c
6. ThÃªm cÃ¡c khuyáº¿n nghá»‹ cá»¥ thá»ƒ vÃ  thá»±c táº¿

HÃ£y viáº¿t láº¡i toÃ n bá»™ bÃ¡o cÃ¡o theo cáº¥u trÃºc chuáº©n, Ä‘áº£m báº£o:
- NgÃ´n ngá»¯ chuyÃªn nghiá»‡p nhÆ°ng dá»… hiá»ƒu
- ThÃ´ng tin chÃ­nh xÃ¡c vÃ  khoa há»c
- Cáº¥u trÃºc rÃµ rÃ ng vá»›i cÃ¡c tiÃªu Ä‘á» phÃ¹ há»£p
- Ná»™i dung Ä‘áº§y Ä‘á»§ vÃ  toÃ n diá»‡n

Chá»‰ tráº£ vá» ná»™i dung bÃ¡o cÃ¡o cuá»‘i cÃ¹ng, khÃ´ng cáº§n giáº£i thÃ­ch thÃªm.
"""
    
    try:
        final_report = call_gemini(gemini_prompt, model_name="models/gemini-2.0-pro")
        return final_report.strip()
    except Exception as e:
        # Fallback náº¿u Gemini lá»—i
        fallback_report = f"# {template_name}\n\n"
        fallback_report += f"**YÃªu cáº§u:** {user_prompt}\n\n"
        for section_title, data in results.items():
            fallback_report += f"## {section_title}\n\n{data['content']}\n\n"
        fallback_report += f"\nâš ï¸ LÆ°u Ã½: BÃ¡o cÃ¡o nÃ y chÆ°a Ä‘Æ°á»£c tá»•ng há»£p bá»Ÿi AI do lá»—i ká»¹ thuáº­t: {str(e)}"
        return fallback_report

def generate_response(prompt: str,
                      temperature=0.1, top_p=0.9, top_k=50,
                      repetition_penalty=1.0, do_sample=True,
                      max_new_tokens=1024):
    """HÃ m chÃ­nh gá»i tá»« FastAPI - Táº¡o bÃ¡o cÃ¡o theo template"""

    generation_params = {
        "max_new_tokens": max_new_tokens,
        "temperature": temperature,
        "top_p": top_p,
        "top_k": top_k,
        "repetition_penalty": repetition_penalty,
        "do_sample": do_sample
    }

    try:
        # XÃ¡c Ä‘á»‹nh loáº¡i template
        template_type = detect_template_type(prompt)
        template = TEMPLATES[template_type]
        
        # Táº¡o full response thay vÃ¬ stream
        full_response = ""
        
        # Header
        full_response += f"# {template['name']}\n\n"
        full_response += f"**YÃªu cáº§u:** {prompt}\n\n"
        full_response += "=" * 50 + "\n\n"

        results = {}
        
        # Sinh ná»™i dung tá»«ng má»¥c
        for i, section in enumerate(template['sections'], 1):
            section_title = section['title']
            section_description = section['description']
            
            full_response += f"ğŸ“ **Äang xá»­ lÃ½ má»¥c {i}/{len(template['sections'])}: {section_title}**\n\n"
            
            # BÆ°á»›c 1: Táº¡o cÃ¢u há»i vá»›i Gemini
            full_response += "ğŸ¤– Táº¡o cÃ¢u há»i hÆ°á»›ng dáº«n...\n"
            questions = generate_section_questions(prompt, section_title, section_description, template_type)
            
            # BÆ°á»›c 2: Táº¡o prompt chi tiáº¿t cho LLM
            detailed_prompt = f"""
                YÃªu cáº§u gá»‘c: {prompt}

                Má»¥c cáº§n viáº¿t: {section_title}
                MÃ´ táº£: {section_description}

                CÃ¢u há»i hÆ°á»›ng dáº«n:
                {questions}

                HÃ£y viáº¿t ná»™i dung chi tiáº¿t vÃ  chuyÃªn nghiá»‡p cho má»¥c "{section_title}" dá»±a trÃªn cÃ¡c cÃ¢u há»i hÆ°á»›ng dáº«n trÃªn.
                Ná»™i dung cáº§n cÃ³ cáº¥u trÃºc rÃµ rÃ ng, sá»­ dá»¥ng thuáº­t ngá»¯ chuyÃªn mÃ´n phÃ¹ há»£p vÃ  Ä‘áº£m báº£o tÃ­nh khoa há»c.
                """
            
            # BÆ°á»›c 3: Gá»­i tá»›i LLM
            full_response += "âš¡ Sinh ná»™i dung tá»« LLM...\n"
            llm_prompt = build_prompt(detailed_prompt)
            response = send_request(llm_prompt, generation_params)
            
            if isinstance(response, str):
                full_response += f"âŒ Lá»—i: {response}\n"
                continue
                
            # Thu tháº­p response tá»« LLM
            section_content = ""
            for chunk in response.iter_content(chunk_size=None):
                if chunk:
                    decoded = chunk.decode("utf-8")
                    section_content += decoded
            
            # Parse Ä‘á»ƒ láº¥y pháº§n <answer>
            parsed_content = parse_llm_response(section_content)
            
            # LÆ°u káº¿t quáº£
            results[section_title] = {
                'questions': questions,
                'content': parsed_content
            }
            
            # Add thÃ´ng tin táº¡m thá»i (sáº½ Ä‘Æ°á»£c thay tháº¿ báº±ng bÃ¡o cÃ¡o cuá»‘i)
            full_response += f"âœ… **HoÃ n thÃ nh má»¥c: {section_title}**\n"
            full_response += f"Ná»™i dung: {len(parsed_content)} kÃ½ tá»±\n\n"
            time.sleep(0.3)  # TrÃ¡nh spam

        # Táº¡o bÃ¡o cÃ¡o cuá»‘i cÃ¹ng vá»›i Gemini
        full_response += "ğŸ”„ **Äang tá»•ng há»£p bÃ¡o cÃ¡o cuá»‘i cÃ¹ng báº±ng Gemini...**\n\n"
        
        try:
            final_report = create_final_report_with_gemini(template['name'], prompt, results)
            
            # Thay tháº¿ toÃ n bá»™ ná»™i dung báº±ng bÃ¡o cÃ¡o cuá»‘i
            full_response = "=" * 60 + "\n"
            full_response += "ğŸ¯ **BÃO CÃO CUá»I CÃ™NG - ÄÃƒ ÄÆ¯á»¢C Tá»”NG Há»¢P Bá»I AI**\n"
            full_response += "=" * 60 + "\n\n"
            full_response += final_report
            full_response += "\n\n" + "=" * 60 + "\n"
            full_response += "âœ… **HoÃ n thÃ nh bÃ¡o cÃ¡o!**\n"
            full_response += f"ğŸ“Š **Thá»‘ng kÃª:** ÄÃ£ xá»­ lÃ½ {len(template['sections'])} má»¥c"
            
        except Exception as e:
            full_response += f"\nâŒ Lá»—i tá»•ng há»£p bÃ¡o cÃ¡o cuá»‘i: {str(e)}\n"
            full_response += "\nğŸ“‹ **BÃOCÃO Gá»C (chÆ°a tá»•ng há»£p):**\n\n"
            for section_title, data in results.items():
                full_response += f"## {section_title}\n\n{data['content']}\n\n---\n\n"
        
        # Return full response as string Ä‘á»ƒ main.py cÃ³ thá»ƒ xá»­ lÃ½
        return full_response
        
    except Exception as e:
        return f"âŒ Lá»—i tá»•ng thá»ƒ: {str(e)}"