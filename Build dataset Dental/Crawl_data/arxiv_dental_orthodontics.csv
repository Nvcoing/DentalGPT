title,authors,summary,published,link,keyword_used
Computational Orthodontic Force Simulation: A Review,"Waheed Ahmad, Jing Xiong, Zeyang Xia","In orthodontic treatment, the biological response of the tooth, periodontal
ligament, and bone complex to orthodontic force is crucial in influencing
treatment outcomes. The challenge lies in accurately measuring, estimating, and
predicting these forces during clinical procedures. This review aims to fill
the gap in the literature by systematically summarizing existing research on
orthodontic force simulation, examining common loading techniques and
technologies, and discussing the potential for refining the orthodontic force
simulation process. The literature was comprehensively reviewed, with an
emphasis on the exploration of the biological mechanism of tooth movement.
Studies were categorized based on force-loading techniques for both fixed and
invisible orthodontic appliances. Finite element (FE) analysis stands out as
the predominant technique for orthodontic force simulation, with a significant
focus on fixed orthodontics but limited emphasis on invisible orthodontics.
Current orthodontic force simulations tend to be fragmented, often considering
only the instantaneous response to applied forces. There exists an urgent
demand for a sophisticated analytical simulation model. Such a model, possibly
leveraging advanced technologies like deep learning, holds the promise of
forecasting orthodontic treatment outcomes with heightened precision and
efficiency.",2025-03-31T15:13:36Z,http://arxiv.org/abs/2503.24195v1,orthodontics
3D Structure-guided Network for Tooth Alignment in 2D Photograph,"Yulong Dou, Lanzhuju Mei, Dinggang Shen, Zhiming Cui","Orthodontics focuses on rectifying misaligned teeth (i.e., malocclusions),
affecting both masticatory function and aesthetics. However, orthodontic
treatment often involves complex, lengthy procedures. As such, generating a 2D
photograph depicting aligned teeth prior to orthodontic treatment is crucial
for effective dentist-patient communication and, more importantly, for
encouraging patients to accept orthodontic intervention. In this paper, we
propose a 3D structure-guided tooth alignment network that takes 2D photographs
as input (e.g., photos captured by smartphones) and aligns the teeth within the
2D image space to generate an orthodontic comparison photograph featuring
aesthetically pleasing, aligned teeth. Notably, while the process operates
within a 2D image space, our method employs 3D intra-oral scanning models
collected in clinics to learn about orthodontic treatment, i.e., projecting the
pre- and post-orthodontic 3D tooth structures onto 2D tooth contours, followed
by a diffusion model to learn the mapping relationship. Ultimately, the aligned
tooth contours are leveraged to guide the generation of a 2D photograph with
aesthetically pleasing, aligned teeth and realistic textures. We evaluate our
network on various facial photographs, demonstrating its exceptional
performance and strong applicability within the orthodontic industry.",2023-10-17T09:44:30Z,http://arxiv.org/abs/2310.11106v2,orthodontics
Convolutional Neural Networks in Orthodontics: a review,"Szymon Płotka, Tomasz Włodarczyk, Ryszard Szczerba, Przemysław Rokita, Patrycja Bartkowska, Oskar Komisarek, Artur Matthews-Brzozowski, Tomasz Trzciński","Convolutional neural networks (CNNs) are used in many areas of computer
vision, such as object tracking and recognition, security, military, and
biomedical image analysis. This review presents the application of
convolutional neural networks in one of the fields of dentistry - orthodontics.
Advances in medical imaging technologies and methods allow CNNs to be used in
orthodontics to shorten the planning time of orthodontic treatment, including
an automatic search of landmarks on cephalometric X-ray images, tooth
segmentation on Cone-Beam Computed Tomography (CBCT) images or digital models,
and classification of defects on X-Ray panoramic images. In this work, we
describe the current methods, the architectures of deep convolutional neural
networks used, and their implementations, together with a comparison of the
results achieved by them. The promising results and visualizations of the
described studies show that the use of methods based on convolutional neural
networks allows for the improvement of computer-based orthodontic treatment
planning, both by reducing the examination time and, in many cases, by
performing the analysis much more accurately than a manual orthodontist does.",2021-04-18T16:02:30Z,http://arxiv.org/abs/2104.08886v1,orthodontics
"The management of obstructive sleep apnea accompanied with mandibular
  retrognathia across the lifespan from orthodontic perspective","Menghan Zhang, Yuehua Liu","Obstructive sleep apnea (OSA) is a complex disease with complex etiology,
which requires multidisciplinary cooperation in diagnosis and treatment.
Mandibular retrognathia is strongly associated with OSA. Orthodontists can
either correct the mandibular retrognathia of pediatric OSA via various kinds
of orthodontic appliances, following adenoidectomy and tonsillectomy, or
enlarge upper airway by mandibular advancement device (MAD) through
repositioning the mandible and tongue of adult OSA patients. This mini review
was to investigate the therapy of MAD to adult OSA as well as orthodontic
treatment to pediatric OSA.",2023-11-02T15:36:08Z,http://arxiv.org/abs/2311.01324v1,orthodontics
"OrthoGAN:High-Precision Image Generation for Teeth Orthodontic
  Visualization","Feihong Shen, JIngjing Liu, Jianwen Lou, Haizhen Li, Bing Fang, Chenglong Ma, Jin Hao, Yang Feng, Youyi Zheng","Patients take care of what their teeth will be like after the orthodontics.
Orthodontists usually describe the expectation movement based on the original
smile images, which is unconvincing. The growth of deep-learning generative
models change this situation. It can visualize the outcome of orthodontic
treatment and help patients foresee their future teeth and facial appearance.
While previous studies mainly focus on 2D or 3D virtual treatment outcome (VTO)
at a profile level, the problem of simulating treatment outcome at a frontal
facial image is poorly explored. In this paper, we build an efficient and
accurate system for simulating virtual teeth alignment effects in a frontal
facial image. Our system takes a frontal face image of a patient with visible
malpositioned teeth and the patient's 3D scanned teeth model as input, and
progressively generates the visual results of the patient's teeth given the
specific orthodontics planning steps from the doctor (i.e., the specification
of translations and rotations of individual tooth). We design a multi-modal
encoder-decoder based generative model to synthesize identity-preserving
frontal facial images with aligned teeth. In addition, the original image color
information is used to optimize the orthodontic outcomes, making the results
more natural. We conduct extensive qualitative and clinical experiments and
also a pilot study to validate our method.",2022-12-29T03:12:47Z,http://arxiv.org/abs/2212.14162v2,orthodontics
"Using Natural Language Processing to Develop an Automated Orthodontic
  Diagnostic System","Tomoyuki Kajiwara, Chihiro Tanikawa, Yuujin Shimizu, Chenhui Chu, Takashi Yamashiro, Hajime Nagahara","We work on the task of automatically designing a treatment plan from the
findings included in the medical certificate written by the dentist. To develop
an artificial intelligence system that deals with free-form certificates
written by dentists, we annotate the findings and utilized the natural language
processing approach. As a result of the experiment using 990 certificates,
0.585 F1-score was achieved for the task of extracting orthodontic problems
from findings, and 0.584 correlation coefficient with the human ranking was
achieved for the treatment prioritization task.",2019-05-31T13:13:51Z,http://arxiv.org/abs/1905.13601v1,orthodontics
"CephGPT-4: An Interactive Multimodal Cephalometric Measurement and
  Diagnostic System with Visual Large Language Model","Lei Ma, Jincong Han, Zhaoxin Wang, Dian Zhang","Large-scale multimodal language models (LMMs) have achieved remarkable
success in general domains. However, the exploration of diagnostic language
models based on multimodal cephalometric medical data remains limited. In this
paper, we propose a novel multimodal cephalometric analysis and diagnostic
dialogue model. Firstly, a multimodal orthodontic medical dataset is
constructed, comprising cephalometric images and doctor-patient dialogue data,
with automatic analysis of cephalometric landmarks using U-net and generation
of diagnostic reports. Then, the cephalometric dataset and generated diagnostic
reports are separately fine-tuned on Minigpt-4 and VisualGLM. Results
demonstrate that the CephGPT-4 model exhibits excellent performance and has the
potential to revolutionize orthodontic measurement and diagnostic applications.
These innovations hold revolutionary application potential in the field of
orthodontics.",2023-07-01T15:41:12Z,http://arxiv.org/abs/2307.07518v1,orthodontics
"Aligner-induced tooth movements in three dimensions using clinical data
  of two patients","Ignacio Filippon, Christine Tanner, Jeannette A. von Jackowski, Georg Schulz, Tino Töpper, Bert Müller","The effectiveness of a series of optically transparent aligners for
orthodontic treatments depends on the anchoring of each tooth. In contrast with
roots, the crowns' positions and orientations are measurable with intraoral
scans, thus avoiding any X-ray dose. Exemplified by two patients, we
demonstrate that three-dimensional crown movements could be determined with
micrometer precision by registering weekly intraoral scans. The data show the
movement and orientation changes of the individual crowns of the upper and
lower jaws as the result of the forces generated by the series of aligners.
During the first weeks, the canines and incisors were more affected than the
premolars and molars. We detected an overall tooth movement of up to about 1 mm
during a nine-week treatment. The data on these orthodontic treatments indicate
the extent to which actual tooth movement lags behind the treatment plan as
represented by the aligner shapes. The proposed procedure can not only be used
to quantify the clinical outcome of the therapy, but also to improve future
planning of orthodontic treatments for each specific patient. The study should
be treated with caution because only two cases have been investigated and the
approach should be applied to a reasonably large cohort to reach strong
conclusions regarding efficiency and efficacy of the therapeutic approach.",2024-05-16T20:31:45Z,http://arxiv.org/abs/2405.10433v2,orthodontics
"Transformer-Based Tooth Alignment Prediction With Occlusion And
  Collision Constraints","ZhenXing Dong, JiaZhou Chen, YangHui Xu","The planning of digital orthodontic treatment requires providing tooth
alignment, which not only consumes a lot of time and labor to determine
manually but also relays clinical experiences heavily. In this work, we
proposed a lightweight tooth alignment neural network based on
Swin-transformer. We first re-organized 3D point clouds based on virtual arch
lines and converted them into order-sorted multi-channel textures, which
improves the accuracy and efficiency simultaneously. We then designed two new
occlusal loss functions that quantitatively evaluate the occlusal relationship
between the upper and lower jaws. They are important clinical constraints,
first introduced to the best of our knowledge, and lead to cutting-edge
prediction accuracy. To train our network, we collected a large digital
orthodontic dataset that has 591 clinical cases, including various complex
clinical cases. This dataset will benefit the community after its release since
there is no open dataset so far. Furthermore, we also proposed two new
orthodontic dataset augmentation methods considering tooth spatial distribution
and occlusion. We evaluated our method with this dataset and extensive
experiments, including comparisons with STAT methods and ablation studies, and
demonstrate the high prediction accuracy of our method.",2024-10-28T07:54:07Z,http://arxiv.org/abs/2410.20806v3,orthodontics
Automatic Recognition of Landmarks on Digital Dental Models,"Brénainn Woodsend, Eirini Koufoudaki, Peter A. Mossey, Ping Lin","Fundamental to improving Dental and Orthodontic treatments is the ability to
quantitatively assess and cross-compare their outcomes. Such assessments
require calculating distances and angles from 3D coordinates of dental
landmarks. The costly and repetitive task of hand-labelling dental models
impedes studies requiring large sample size to penetrate statistical noise. We
have developed techniques and software implementing these techniques to map out
automatically, 3D dental scans. This process is divided into consecutive steps
- determining a model's orientation, separating and identifying the individual
tooth and finding landmarks on each tooth - described in this paper. Examples
to demonstrate techniques and the software and discussions on remaining issues
are provided as well. The software is originally designed to automate Modified
Huddard Bodemham (MHB) landmarking for assessing cleft lip/palate patients.
Currently only MHB landmarks are supported, but is extendable to any
predetermined landmarks. This software, coupled with intra-oral scanning
innovation, should supersede the arduous and error prone plaster model and
caliper approach to Dental research and provide a stepping-stone towards
automation of routine clinical assessments such as ""index of orthodontic
treatment need"" (IOTN).",2020-12-23T20:14:00Z,http://arxiv.org/abs/2012.12946v1,orthodontics
CEPHA29: Automatic Cephalometric Landmark Detection Challenge 2023,"Muhammad Anwaar Khalid, Kanwal Zulfiqar, Ulfat Bashir, Areeba Shaheen, Rida Iqbal, Zarnab Rizwan, Ghina Rizwan, Muhammad Moazam Fraz","Quantitative cephalometric analysis is the most widely used clinical and
research tool in modern orthodontics. Accurate localization of cephalometric
landmarks enables the quantification and classification of anatomical
abnormalities, however, the traditional manual way of marking these landmarks
is a very tedious job. Endeavours have constantly been made to develop
automated cephalometric landmark detection systems but they are inadequate for
orthodontic applications. The fundamental reason for this is that the amount of
publicly available datasets as well as the images provided for training in
these datasets are insufficient for an AI model to perform well. To facilitate
the development of robust AI solutions for morphometric analysis, we organise
the CEPHA29 Automatic Cephalometric Landmark Detection Challenge in conjunction
with IEEE International Symposium on Biomedical Imaging (ISBI 2023). In this
context, we provide the largest known publicly available dataset, consisting of
1000 cephalometric X-ray images. We hope that our challenge will not only
derive forward research and innovation in automatic cephalometric landmark
identification but will also signal the beginning of a new era in the
discipline.",2022-12-09T12:25:58Z,http://arxiv.org/abs/2212.04808v2,orthodontics
"Two-Stage Mesh Deep Learning for Automated Tooth Segmentation and
  Landmark Localization on 3D Intraoral Scans","Tai-Hsien Wu, Chunfeng Lian, Sanghee Lee, Matthew Pastewait, Christian Piers, Jie Liu, Fang Wang, Li Wang, Chiung-Ying Chiu, Wenchi Wang, Christina Jackson, Wei-Lun Chao, Dinggang Shen, Ching-Chang Ko","Accurately segmenting teeth and identifying the corresponding anatomical
landmarks on dental mesh models are essential in computer-aided orthodontic
treatment. Manually performing these two tasks is time-consuming, tedious, and,
more importantly, highly dependent on orthodontists' experiences due to the
abnormality and large-scale variance of patients' teeth. Some machine
learning-based methods have been designed and applied in the orthodontic field
to automatically segment dental meshes (e.g., intraoral scans). In contrast,
the number of studies on tooth landmark localization is still limited. This
paper proposes a two-stage framework based on mesh deep learning (called
TS-MDL) for joint tooth labeling and landmark identification on raw intraoral
scans. Our TS-MDL first adopts an end-to-end \emph{i}MeshSegNet method (i.e., a
variant of the existing MeshSegNet with both improved accuracy and efficiency)
to label each tooth on the downsampled scan. Guided by the segmentation
outputs, our TS-MDL further selects each tooth's region of interest (ROI) on
the original mesh to construct a light-weight variant of the pioneering
PointNet (i.e., PointNet-Reg) for regressing the corresponding landmark
heatmaps. Our TS-MDL was evaluated on a real-clinical dataset, showing
promising segmentation and localization performance. Specifically,
\emph{i}MeshSegNet in the first stage of TS-MDL reached an averaged Dice
similarity coefficient (DSC) at \textcolor[rgb]{0,0,0}{$0.964\pm0.054$},
significantly outperforming the original MeshSegNet. In the second stage,
PointNet-Reg achieved a mean absolute error (MAE) of $0.597\pm0.761 \, mm$ in
distances between the prediction and ground truth for $66$ landmarks, which is
superior compared with other networks for landmark detection. All these results
suggest the potential usage of our TS-MDL in orthodontics.",2021-09-24T13:00:26Z,http://arxiv.org/abs/2109.11941v4,orthodontics
"CHaRNet: Conditioned Heatmap Regression for Robust Dental Landmark
  Localization","José Rodríguez-Ortega, Francisco Pérez-Hernández, Siham Tabik","Identifying anatomical landmarks in 3D dental models is vital for orthodontic
treatment, yet manual placement is complex and time-consuming. Although some
machine learning approaches have been proposed for automatic tooth landmark
detection in 3D Intraoral Scans (IOS), none provide a fully end-to-end solution
that bypasses teeth segmentation, limiting practical applicability. We
introduce CHaRNet (Conditioned Heatmap Regression Network), the first fully
end-to-end deep learning framework for tooth landmark detection in 3D IOS.
Unlike traditional two-stage workflows that segment teeth before detecting
landmarks, CHaRNet directly operates on the input point cloud, thus reducing
complexity and computational overhead. Our method integrates four modules: (1)
a point cloud encoder, (2) a point cloud decoder with a heatmap regression
head, (3) a teeth presence classification head, and (4) the novel Conditioned
Heatmap Regression (CHaR) module. By leveraging teeth presence classification,
the CHaR module dynamically adapts to missing teeth and enhances detection
accuracy in complex dental models. We evaluate CHaRNet using five point cloud
learning algorithms on a clinical dataset of 1,214 annotated 3D models. Both
the dataset and code will be publicly released to address the lack of open
datasets in orthodontics and inspire further research. CHaRNet achieves a Mean
Euclidean Distance Error (MEDE) of 0.51 mm on typical dental models and 1.28 mm
across all dentition types, with corresponding Mean Success Rates (MSR) of
87.06% and 82.40%, respectively. Notably, it exhibits robust performance on
irregular geometries, including models with missing teeth. This end-to-end
approach streamlines orthodontic workflows, enhances 3D IOS analysis precision,
and supports efficient computer-assisted treatment planning.",2025-01-22T18:35:57Z,http://arxiv.org/abs/2501.13073v4,orthodontics
Cone-beam CT for Dental Radiography,"Kaspar Höschel, Janos Juhasz","The cone beam computed tomography (CBCT) technique was first inserted in
dental imaging 15 years ago. Due to this technique 3D imaging in dentistry has
been excessively changed. The purpose beyond using CBCT instead of computed
tomography (CT) imaging is that CT can not be used in many cases in dentistry,
in addition to the higher radiation and cost of CT. Nowadays, CBCT can be
applied in diagnostics for several dental specialties because of the variety of
services it offers and the specification of use. In contrast to CT, CBCT has
shown great benefits in endodontics, implant planning oral and maxillofacial
surgery and even in orthodontics.",2018-12-10T16:13:38Z,http://arxiv.org/abs/1812.03900v1,orthodontics
"Step-by-Step Guide to Conducting Meta-Analysis of Dichotomous Outcomes
  Using RevMan in Dental Research Step-by-Step Guide to Conducting
  Meta-Analysis of Dichotomous Outcomes Using RevMan in Dental Research","Hoi-Jeong Lim, Su-Hyeon Park","Meta-analysis is a statistical method that combines the results of individual
studies on the same topic. This method is becoming popular, due to providing
the combined result that individual studies cannot provide and giving a more
precise result. Despite meta-analysis having such significance, there are few
Korean guides for the use of the Review Manager (RevMan) software. This study
will provide a step-by-step guide, using orthodontic mini-screw as a dental
example, to help researcher carry out meta-analysis more easily and accurately.",2025-02-27T11:54:55Z,http://arxiv.org/abs/2502.20019v1,orthodontics
Dense Representative Tooth Landmark/axis Detection Network on 3D Model,"Guangshun Wei, Zhiming Cui, Jie Zhu, Lei Yang, Yuanfeng Zhou, Pradeep Singh, Min Gu, Wenping Wang","Artificial intelligence (AI) technology is increasingly used for digital
orthodontics, but one of the challenges is to automatically and accurately
detect tooth landmarks and axes. This is partly because of sophisticated
geometric definitions of them, and partly due to large variations among
individual tooth and across different types of tooth. As such, we propose a
deep learning approach with a labeled dataset by professional dentists to the
tooth landmark/axis detection on tooth model that are crucial for orthodontic
treatments. Our method can extract not only tooth landmarks in the form of
point (e.g. cusps), but also axes that measure the tooth angulation and
inclination. The proposed network takes as input a 3D tooth model and predicts
various types of the tooth landmarks and axes. Specifically, we encode the
landmarks and axes as dense fields defined on the surface of the tooth model.
This design choice and a set of added components make the proposed network more
suitable for extracting sparse landmarks from a given 3D tooth model. Extensive
evaluation of the proposed method was conducted on a set of dental models
prepared by experienced dentists. Results show that our method can produce
tooth landmarks with high accuracy. Our method was examined and justified via
comparison with the state-of-the-art methods as well as the ablation studies.",2021-11-08T00:42:22Z,http://arxiv.org/abs/2111.04212v2,orthodontics
"'Aariz: A Benchmark Dataset for Automatic Cephalometric Landmark
  Detection and CVM Stage Classification","Muhammad Anwaar Khalid, Kanwal Zulfiqar, Ulfat Bashir, Areeba Shaheen, Rida Iqbal, Zarnab Rizwan, Ghina Rizwan, Muhammad Moazam Fraz","The accurate identification and precise localization of cephalometric
landmarks enable the classification and quantification of anatomical
abnormalities. The traditional way of marking cephalometric landmarks on
lateral cephalograms is a monotonous and time-consuming job. Endeavours to
develop automated landmark detection systems have persistently been made,
however, they are inadequate for orthodontic applications due to unavailability
of a reliable dataset. We proposed a new state-of-the-art dataset to facilitate
the development of robust AI solutions for quantitative morphometric analysis.
The dataset includes 1000 lateral cephalometric radiographs (LCRs) obtained
from 7 different radiographic imaging devices with varying resolutions, making
it the most diverse and comprehensive cephalometric dataset to date. The
clinical experts of our team meticulously annotated each radiograph with 29
cephalometric landmarks, including the most significant soft tissue landmarks
ever marked in any publicly available dataset. Additionally, our experts also
labelled the cervical vertebral maturation (CVM) stage of the patient in a
radiograph, making this dataset the first standard resource for CVM
classification. We believe that this dataset will be instrumental in the
development of reliable automated landmark detection frameworks for use in
orthodontics and beyond.",2023-02-15T17:31:56Z,http://arxiv.org/abs/2302.07797v1,orthodontics
"Generative Adversarial Networks for Dental Patient Identity Protection
  in Orthodontic Educational Imaging","Mingchuan Tian, Wilson Weixun Lu, Kelvin Weng Chiong Foong, Eugene Loh","Objectives: This research introduces a novel area-preserving Generative
Adversarial Networks (GAN) inversion technique for effectively de-identifying
dental patient images. This innovative method addresses privacy concerns while
preserving key dental features, thereby generating valuable resources for
dental education and research.
  Methods: We enhanced the existing GAN Inversion methodology to maximize the
preservation of dental characteristics within the synthesized images. A
comprehensive technical framework incorporating several deep learning models
was developed to provide end-to-end development guidance and practical
application for image de-identification.
  Results: Our approach was assessed with varied facial pictures, extensively
used for diagnosing skeletal asymmetry and facial anomalies. Results
demonstrated our model's ability to adapt the context from one image to
another, maintaining compatibility, while preserving dental features essential
for oral diagnosis and dental education. A panel of five clinicians conducted
an evaluation on a set of original and GAN-processed images. The generated
images achieved effective de-identification, maintaining the realism of
important dental features and were deemed useful for dental diagnostics and
education.
  Clinical Significance: Our GAN model and the encompassing framework can
streamline the de-identification process of dental patient images, enhancing
efficiency in dental education. This method improves students' diagnostic
capabilities by offering more exposure to orthodontic malocclusions.
Furthermore, it facilitates the creation of de-identified datasets for broader
2D image research at major research institutions.",2023-07-05T04:14:57Z,http://arxiv.org/abs/2307.02019v1,orthodontics
"Automatic Tooth Arrangement with Joint Features of Point and Mesh
  Representations via Diffusion Probabilistic Models","Changsong Lei, Mengfei Xia, Shaofeng Wang, Yaqian Liang, Ran Yi, Yuhui Wen, Yongjin Liu","Tooth arrangement is a crucial step in orthodontics treatment, in which
aligning teeth could improve overall well-being, enhance facial aesthetics, and
boost self-confidence. To improve the efficiency of tooth arrangement and
minimize errors associated with unreasonable designs by inexperienced
practitioners, some deep learning-based tooth arrangement methods have been
proposed. Currently, most existing approaches employ MLPs to model the
nonlinear relationship between tooth features and transformation matrices to
achieve tooth arrangement automatically. However, the limited datasets (which
to our knowledge, have not been made public) collected from clinical practice
constrain the applicability of existing methods, making them inadequate for
addressing diverse malocclusion issues. To address this challenge, we propose a
general tooth arrangement neural network based on the diffusion probabilistic
model. Conditioned on the features extracted from the dental model, the
diffusion probabilistic model can learn the distribution of teeth
transformation matrices from malocclusion to normal occlusion by gradually
denoising from a random variable, thus more adeptly managing real orthodontic
data. To take full advantage of effective features, we exploit both mesh and
point cloud representations by designing different encoding networks to extract
the tooth (local) and jaw (global) features, respectively. In addition to
traditional metrics ADD, PA-ADD, CSA, and ME_{rot}, we propose a new evaluation
metric based on dental arch curves to judge whether the generated teeth meet
the individual normal occlusion. Experimental results demonstrate that our
proposed method achieves state-of-the-art tooth alignment results and
satisfactory occlusal relationships between dental arches. We will publish the
code and dataset.",2023-12-23T02:27:15Z,http://arxiv.org/abs/2312.15139v1,orthodontics
TeethDreamer: 3D Teeth Reconstruction from Five Intra-oral Photographs,"Chenfan Xu, Zhentao Liu, Yuan Liu, Yulong Dou, Jiamin Wu, Jiepeng Wang, Minjiao Wang, Dinggang Shen, Zhiming Cui","Orthodontic treatment usually requires regular face-to-face examinations to
monitor dental conditions of the patients. When in-person diagnosis is not
feasible, an alternative is to utilize five intra-oral photographs for remote
dental monitoring. However, it lacks of 3D information, and how to reconstruct
3D dental models from such sparse view photographs is a challenging problem. In
this study, we propose a 3D teeth reconstruction framework, named TeethDreamer,
aiming to restore the shape and position of the upper and lower teeth. Given
five intra-oral photographs, our approach first leverages a large diffusion
model's prior knowledge to generate novel multi-view images with known poses to
address sparse inputs and then reconstructs high-quality 3D teeth models by
neural surface reconstruction. To ensure the 3D consistency across generated
views, we integrate a 3D-aware feature attention mechanism in the reverse
diffusion process. Moreover, a geometry-aware normal loss is incorporated into
the teeth reconstruction process to enhance geometry accuracy. Extensive
experiments demonstrate the superiority of our method over current
state-of-the-arts, giving the potential to monitor orthodontic treatment
remotely. Our code is available at
https://github.com/ShanghaiTech-IMPACT/TeethDreamer",2024-07-16T06:24:32Z,http://arxiv.org/abs/2407.11419v1,orthodontics
Transformation trees -- documentation of multimodal image registration,"Agnieszka Anna Tomaka, Dariusz Pojda, Michał Tarnawski, Leszek Luchowski","Multimodal image registration plays a key role in creating digital patient
models by combining data from different imaging techniques into a single
coordinate system. This process often involves multiple sequential and
interconnected transformations, which must be well-documented to ensure
transparency and reproducibility. In this paper, we propose the use of
transformation trees as a method for structured recording and management of
these transformations. This approach has been implemented in the dpVision
software and uses a dedicated .dpw file format to store hierarchical
relationships between images, transformations, and motion data. Transformation
trees allow precise tracking of all image processing steps, reduce the need to
store multiple copies of the same data, and enable the indirect registration of
images that do not share common reference points. This improves the
reproducibility of the analyses and facilitates later processing and
integration of images from different sources. The practical application of this
method is demonstrated with examples from orthodontics, including the
integration of 3D face scans, intraoral scans, and CBCT images, as well as the
documentation of mandibular motion. Beyond orthodontics, this method can be
applied in other fields that require systematic management of image
registration processes, such as maxillofacial surgery, oncology, and
biomechanical analysis. Maintaining long-term data consistency is essential for
both scientific research and clinical practice. It enables easier comparison of
results in longitudinal studies, improves retrospective analysis, and supports
the development of artificial intelligence algorithms by providing standardized
and well-documented datasets. The proposed approach enhances data organization,
allows for efficient analysis, and facilitates the reuse of information in
future studies and diagnostic procedures.",2025-01-31T13:49:16Z,http://arxiv.org/abs/2501.19140v2,orthodontics
"Prognostic factors associated with success rates of posterior
  orthodontic miniscrew implant","Sung-Bin Hong, Budi Kusnoto, Eunjeong Kim, Ellen A BeGole, Hyeon-Shik Hwang, Hoi-Jeong Lim","Three electronic searches were conducted to obtain articles in English
limited to clinical human studies published prior to March 2015. The outcome
measure was the success of MIs. Patient factors included age, gender, and jaw;
the MI factors included length and diameter. A metaanalysis was then performed
based on 17 individual studies. The quality of each study was assessed for
nonrandomized studies and quantified using the NewcastleOttawa Scale. The
outcome of the metaanalysis was a combined OR. Subgroup and sensitivity
analyses based on the study design, study quality, and sample size of MI were
performed.",2015-10-09T19:54:21Z,http://arxiv.org/abs/1510.02790v2,orthodontics
Bayesian Networks Analysis of Malocclusion Data,"Marco Scutari, Pietro Auconi, Guido Caldarelli, Lorenzo Franchi","In this paper we use Bayesian networks to determine and visualise the
interactions among various Class III malocclusion maxillofacial features during
growth and treatment. We start from a sample of 143 patients characterised
through a series of a maximum of 21 different craniofacial features. We
estimate a network model from these data and we test its consistency by
verifying some commonly accepted hypotheses on the evolution of these
disharmonies by means of Bayesian statistics. We show that untreated subjects
develop different Class III craniofacial growth patterns as compared to
patients submitted to orthodontic treatment with rapid maxillary expantion and
facemask therapy. Among treated patients the CoA segment (the maxillary length)
and the ANB angle (the antero-posterior relation of the maxilla to the
mandible) seem to be the skeletal subspaces that receive the main effect of the
treatment.",2017-02-09T17:57:14Z,http://arxiv.org/abs/1702.03862v3,orthodontics
"Mandibular Teeth Movement Variations in Tipping Scenario: A Finite
  Element Study on Several Patients","Torkan Gholamalizadeh, Sune Darkner, Paolo Maria Cattaneo, Peter Søndergaard, Kenny Erleben","Previous studies on computational modeling of tooth movement in orthodontic
treatments are limited to a single model and fail in generalizing the
simulation results to other patients. To this end, we consider multiple
patients and focus on tooth movement variations under the identical load and
boundary conditions both for intra- and inter-patient analyses. We introduce a
novel computational analysis tool based on finite element models (FEMs)
addressing how to assess initial tooth displacement in the mandibular dentition
across different patients for uncontrolled tipping scenarios with different
load magnitudes applied to the mandibular dentition. This is done by modeling
the movement of each patient's tooth as a nonlinear function of both load and
tooth size. As the size of tooth can affect the resulting tooth displacement, a
combination of two clinical biomarkers obtained from the tooth anatomy, i.e.,
crown height and root volume, is considered to make the proposed model
generalizable to different patients and teeth.",2020-10-11T14:51:21Z,http://arxiv.org/abs/2010.05258v1,orthodontics
"An Attention-Guided Deep Regression Model for Landmark Detection in
  Cephalograms","Zhusi Zhong, Jie Li, Zhenxi Zhang, Zhicheng Jiao, Xinbo Gao","Cephalometric tracing method is usually used in orthodontic diagnosis and
treatment planning. In this paper, we propose a deep learning based framework
to automatically detect anatomical landmarks in cephalometric X-ray images. We
train the deep encoder-decoder for landmark detection, and combine global
landmark configuration with local high-resolution feature responses. The
proposed frame-work is based on 2-stage u-net, regressing the multi-channel
heatmaps for land-mark detection. In this framework, we embed attention
mechanism with global stage heatmaps, guiding the local stage inferring, to
regress the local heatmap patches in a high resolution. Besides, the Expansive
Exploration strategy improves robustness while inferring, expanding the
searching scope without increasing model complexity. We have evaluated our
framework in the most widely-used public dataset of landmark detection in
cephalometric X-ray images. With less computation and manually tuning, our
framework achieves state-of-the-art results.",2019-06-17T15:11:31Z,http://arxiv.org/abs/1906.07549v3,orthodontics
"3D and 4D printing in dentistry and maxillofacial surgery: Recent
  advances and future perspectives","Danial Khorsandi, Amir Fahimipour, Payam Abasian, Sepehr Sadeghpour Saber, Mahla Seyedi, Sonia Ghanavati, Amir Ahmad, Andrea Amoretti De Stephanis, Fatemeh Taghavinezhad, Anna Leonova, Reza Mohammadinejad, Majid Shabani, Barbara Mazzolai, Virgilio Mattoli, Franklin R. Tay, Pooyan Makvandi","3D and 4D printing are cutting-edge technologies for precise and expedited
manufacturing of objects ranging from plastic to metal. Recent advances in 3D
and 4D printing technologies in dentistry and maxillofacial surgery enable
dentists to custom design and print surgical drill guides, temporary and
permanent crowns and bridges, orthodontic appliances and orthotics, implants,
mouthguards for drug delivery. In the present review, different 3D printing
technologies available for use in dentistry are highlighted together with a
critique on the materials available for printing. Recent reports of the
application of these printed platformed are highlighted to enable readers
appreciate the progress in 3D/4D printing in dentistry.",2021-03-29T09:39:26Z,http://arxiv.org/abs/2103.15455v1,orthodontics
S-R2F2U-Net: A single-stage model for teeth segmentation,"Mrinal Kanti Dhar, Mou Deb","Precision tooth segmentation is crucial in the oral sector because it
provides location information for orthodontic therapy, clinical diagnosis, and
surgical treatments. In this paper, we investigate residual, recurrent, and
attention networks to segment teeth from panoramic dental images. Based on our
findings, we suggest three single-stage models: Single Recurrent R2U-Net
(S-R2U-Net), Single Recurrent Filter Double R2U-Net (S-R2F2U-Net), and Single
Recurrent Attention Enabled Filter Double (S-R2F2-Attn-U-Net). Particularly,
S-R2F2U-Net outperforms state-of-the-art models in terms of accuracy and dice
score. A hybrid loss function combining the cross-entropy loss and dice loss is
used to train the model. In addition, it reduces around 45% of model parameters
compared to the R2U-Net model. Models are trained and evaluated on a benchmark
dataset containing 1500 dental panoramic X-ray images. S-R2F2U-Net achieves
97.31% of accuracy and 93.26% of dice score, showing superiority over the
state-of-the-art methods. Codes are available at
https://github.com/mrinal054/teethSeg_sr2f2u-net.git.",2022-04-06T17:07:09Z,http://arxiv.org/abs/2204.02939v2,orthodontics
"Radious: Unveiling the Enigma of Dental Radiology with BEIT Adaptor and
  Mask2Former in Semantic Segmentation","Mohammad Mashayekhi, Sara Ahmadi Majd, Arian Amiramjadi, Babak Mashayekhi","X-ray images are the first steps for diagnosing and further treating dental
problems. So, early diagnosis prevents the development and increase of oral and
dental diseases. In this paper, we developed a semantic segmentation algorithm
based on BEIT adaptor and Mask2Former to detect and identify teeth, roots, and
multiple dental diseases and abnormalities such as pulp chamber, restoration,
endodontics, crown, decay, pin, composite, bridge, pulpitis, orthodontics,
radicular cyst, periapical cyst, cyst, implant, and bone graft material in
panoramic, periapical, and bitewing X-ray images. We compared the result of our
algorithm to two state-of-the-art algorithms in image segmentation named:
Deeplabv3 and Segformer on our own data set. We discovered that Radious
outperformed those algorithms by increasing the mIoU scores by 9% and 33% in
Deeplabv3+ and Segformer, respectively.",2023-05-10T15:15:09Z,http://arxiv.org/abs/2305.06236v1,orthodontics
"Enhanced Masked Image Modeling for Analysis of Dental Panoramic
  Radiographs","Amani Almalki, Longin Jan Latecki","The computer-assisted radiologic informative report has received increasing
research attention to facilitate diagnosis and treatment planning for dental
care providers. However, manual interpretation of dental images is limited,
expensive, and time-consuming. Another barrier in dental imaging is the limited
number of available images for training, which is a challenge in the era of
deep learning. This study proposes a novel self-distillation (SD) enhanced
self-supervised learning on top of the masked image modeling (SimMIM)
Transformer, called SD-SimMIM, to improve the outcome with a limited number of
dental radiographs. In addition to the prediction loss on masked patches,
SD-SimMIM computes the self-distillation loss on the visible patches. We apply
SD-SimMIM on dental panoramic X-rays for teeth numbering, detection of dental
restorations and orthodontic appliances, and instance segmentation tasks. Our
results show that SD-SimMIM outperforms other self-supervised learning methods.
Furthermore, we augment and improve the annotation of an existing dataset of
panoramic X-rays.",2023-06-18T19:20:38Z,http://arxiv.org/abs/2306.10623v1,orthodontics
ToothSegNet: Image Degradation meets Tooth Segmentation in CBCT Images,"Jiaxiang Liu, Tianxiang Hu, Yang Feng, Wanghui Ding, Zuozhu Liu","In computer-assisted orthodontics, three-dimensional tooth models are
required for many medical treatments. Tooth segmentation from cone-beam
computed tomography (CBCT) images is a crucial step in constructing the models.
However, CBCT image quality problems such as metal artifacts and blurring
caused by shooting equipment and patients' dental conditions make the
segmentation difficult. In this paper, we propose ToothSegNet, a new framework
which acquaints the segmentation model with generated degraded images during
training. ToothSegNet merges the information of high and low quality images
from the designed degradation simulation module using channel-wise cross fusion
to reduce the semantic gap between encoder and decoder, and also refines the
shape of tooth prediction through a structural constraint loss. Experimental
results suggest that ToothSegNet produces more precise segmentation and
outperforms the state-of-the-art medical image segmentation methods.",2023-07-05T01:41:24Z,http://arxiv.org/abs/2307.01979v1,orthodontics
"PainSeeker: An Automated Method for Assessing Pain in Rats Through
  Facial Expressions","Liu Liu, Guang Li, Dingfan Deng, Jinhua Yu, Yuan Zong","In this letter, we aim to investigate whether laboratory rats' pain can be
automatically assessed through their facial expressions. To this end, we began
by presenting a publicly available dataset called RatsPain, consisting of 1,138
facial images captured from six rats that underwent an orthodontic treatment
operation. Each rat' facial images in RatsPain were carefully selected from
videos recorded either before or after the operation and well labeled by eight
annotators according to the Rat Grimace Scale (RGS). We then proposed a novel
deep learning method called PainSeeker for automatically assessing pain in rats
via facial expressions. PainSeeker aims to seek pain-related facial local
regions that facilitate learning both pain discriminative and head pose robust
features from facial expression images. To evaluate the PainSeeker, we
conducted extensive experiments on the RatsPain dataset. The results
demonstrate the feasibility of assessing rats' pain from their facial
expressions and also verify the effectiveness of the proposed PainSeeker in
addressing this emerging but intriguing problem. The RasPain dataset can be
freely obtained from https://github.com/xhzongyuan/RatsPain.",2023-11-06T15:49:11Z,http://arxiv.org/abs/2311.03205v1,orthodontics
FDNet: Feature Decoupled Segmentation Network for Tooth CBCT Image,"Xiang Feng, Chengkai Wang, Chengyu Wu, Yunxiang Li, Yongbo He, Shuai Wang, Yaiqi Wang","Precise Tooth Cone Beam Computed Tomography (CBCT) image segmentation is
crucial for orthodontic treatment planning. In this paper, we propose FDNet, a
Feature Decoupled Segmentation Network, to excel in the face of the variable
dental conditions encountered in CBCT scans, such as complex artifacts and
indistinct tooth boundaries. The Low-Frequency Wavelet Transform (LF-Wavelet)
is employed to enrich the semantic content by emphasizing the global structural
integrity of the teeth, while the SAM encoder is leveraged to refine the
boundary delineation, thus improving the contrast between adjacent dental
structures. By integrating these dual aspects, FDNet adeptly addresses the
semantic gap, providing a detailed and accurate segmentation. The framework's
effectiveness is validated through rigorous benchmarks, achieving the top Dice
and IoU scores of 85.28% and 75.23%, respectively. This innovative decoupling
of semantic and boundary features capitalizes on the unique strengths of each
element to elevate the quality of segmentation performance.",2023-11-11T12:00:24Z,http://arxiv.org/abs/2311.06551v2,orthodontics
Boundary feature fusion network for tooth image segmentation,"Dongping Zhang, Zheng Li, Fangao Zeng, Yutong Wei","Tooth segmentation is a critical technology in the field of medical image
segmentation, with applications ranging from orthodontic treatment to human
body identification and dental pathology assessment. Despite the development of
numerous tooth image segmentation models by researchers, a common shortcoming
is the failure to account for the challenges of blurred tooth boundaries.
Dental diagnostics require precise delineation of tooth boundaries. This paper
introduces an innovative tooth segmentation network that integrates boundary
information to address the issue of indistinct boundaries between teeth and
adjacent tissues. This network's core is its boundary feature extraction
module, which is designed to extract detailed boundary information from
high-level features. Concurrently, the feature cross-fusion module merges
detailed boundary and global semantic information in a synergistic way,
allowing for stepwise layer transfer of feature information. This method
results in precise tooth segmentation. In the most recent STS Data Challenge,
our methodology was rigorously tested and received a commendable overall score
of 0.91. When compared to other existing approaches, this score demonstrates
our method's significant superiority in segmenting tooth boundaries.",2024-09-06T02:12:21Z,http://arxiv.org/abs/2409.03982v1,orthodontics
"Evaluating the Suitability of Different Intraoral Scan Resolutions for
  Deep Learning-Based Tooth Segmentation","Daron Weekley, Jace Duckworth, Anastasiia Sukhanova, Ananya Jana","Intraoral scans are widely used in digital dentistry for tasks such as dental
restoration, treatment planning, and orthodontic procedures. These scans
contain detailed topological information, but manual annotation of these scans
remains a time-consuming task. Deep learning-based methods have been developed
to automate tasks such as tooth segmentation. A typical intraoral scan contains
over 200,000 mesh cells, making direct processing computationally expensive.
Models are often trained on downsampled versions, typically with 10,000 or
16,000 cells. Previous studies suggest that downsampling may degrade
segmentation accuracy, but the extent of this degradation remains unclear.
Understanding the extent of degradation is crucial for deploying ML models on
edge devices. This study evaluates the extent of performance degradation with
decreasing resolution. We train a deep learning model (PointMLP) on intraoral
scans decimated to 16K, 10K, 8K, 6K, 4K, and 2K mesh cells. Models trained at
lower resolutions are tested on high-resolution scans to assess performance.
Our goal is to identify a resolution that balances computational efficiency and
segmentation accuracy.",2025-02-26T19:30:29Z,http://arxiv.org/abs/2502.19515v1,orthodontics
"GeoT: Geometry-guided Instance-dependent Transition Matrix for
  Semi-supervised Tooth Point Cloud Segmentation","Weihao Yu, Xiaoqing Guo, Chenxin Li, Yifan Liu, Yixuan Yuan","Achieving meticulous segmentation of tooth point clouds from intra-oral scans
stands as an indispensable prerequisite for various orthodontic applications.
Given the labor-intensive nature of dental annotation, a significant amount of
data remains unlabeled, driving increasing interest in semi-supervised
approaches. One primary challenge of existing semi-supervised medical
segmentation methods lies in noisy pseudo labels generated for unlabeled data.
To address this challenge, we propose GeoT, the first framework that employs
instance-dependent transition matrix (IDTM) to explicitly model noise in pseudo
labels for semi-supervised dental segmentation. Specifically, to handle the
extensive solution space of IDTM arising from tens of thousands of dental
points, we introduce tooth geometric priors through two key components:
point-level geometric regularization (PLGR) to enhance consistency between
point adjacency relationships in 3D and IDTM spaces, and class-level geometric
smoothing (CLGS) to leverage the fixed spatial distribution of tooth categories
for optimal IDTM estimation. Extensive experiments performed on the public
Teeth3DS dataset and private dataset demonstrate that our method can make full
utilization of unlabeled data to facilitate segmentation, achieving performance
comparable to fully supervised methods with only $20\%$ of the labeled data.",2025-03-21T09:43:57Z,http://arxiv.org/abs/2503.16976v1,orthodontics
"A simulator for maxillo-facial surgery integrating cephalometry and
  orthodontia","Georges Bettega, Yohan Payan, Benoit Mollard, Anthony Boyer, Bernard Raphaël, Stéphane Lavallee","Objectives : This paper presents a new simulator for maxillo-facial surgery,
that gathers the dental and the maxillo-facial analyses together into a single
computer-assisted procedure. The idea is first to propose a repositioning of
the maxilla, via the introduction of a 3D cephalometry, applied to a 3D virtual
model of the patient's skull. Then, orthodontic data are integrated into this
model, thanks to optical measurements of teeth plaster casts. Materials and
Methods : The feasibility of the maxillo-facial demonstrator was first
evaluated on a dry skull. To simulate malformations (and thus to simulate a
""real"" patient), the skull was modified and manually cut by the surgeon, in
order to generate a given maxillo-facial malformation (with asymmetries in the
sagittal, frontal and axial planes). Results : The validation of our simulator
consisted in evaluating its ability to propose a bone repositioning diagnosis
that will put the skull as it was in its original configuration. A first
qualitative validation is provided in this paper, with a 1.5-mm error in the
repositioning diagnosis. Conclusions : These results mainly validate the
concept of a maxillo-facial numerical simulator that integrates 3D cephalometry
and guarantees a correct dental occlusion.",2006-06-16T13:24:47Z,http://arxiv.org/abs/physics/0606149v1,orthodontics
A Novel Hybrid Approach for Cephalometric Landmark Detection,"Mahshid Majd, Farzaneh Shoeleh","Cephalometric analysis has an important role in dentistry and especially in
orthodontics as a treatment planning tool to gauge the size and special
relationships of the teeth, jaws and cranium. The first step of using such
analyses is localizing some important landmarks known as cephalometric
landmarks on craniofacial in x-ray image. The past decade has seen a growing
interest in automating this process. In this paper, a novel hybrid approach is
proposed for automatic detection of cephalometric landmarks. Here, the
landmarks are categorized into three main sets according to their anatomical
characteristics and usage in well-known cephalometric analyses. Consequently,
to have a reliable and accurate detection system, three methods named edge
tracing, weighted template matching, and analysis based estimation are
designed, each of which is consistent and well-suited for one category. Edge
tracing method is suggested to predict those landmarks which are located on
edges. Weighted template matching method is well-suited for landmarks located
in an obvious and specific structure which can be extracted or searchable in a
given x-ray image. The last but not the least method is named analysis based
estimation. This method is based on the fact that in cephalometric analyses the
relations between landmarks are used and the locations of some landmarks are
never used individually. Therefore the third suggested method has a novelty in
estimating the desired relations directly. The effectiveness of the proposed
approach is compared with the state of the art methods and the results were
promising especially in real world applications.",2015-06-12T08:40:38Z,http://arxiv.org/abs/1506.03936v1,orthodontics
"Automatic Calculation of Resolution in Lateral Cephalogram Based on
  Scale Mark Detection","Jia Guo, Shumeng Wang, Huiqi Li","Cephalometric analysis is an important tool for orthodontic diagnosis. At
present, most cephalometric analysis is performed with the help of image
processing techniques. Hence, the resolution between millimeter and pixel is
needed with high accuracy. In cephalometric analysis, a scale is placed in
front of patient's head when taking the radiograph. This study aims to develop
an algorithm to recognize the scale in cephalogram, locate the scale mark and
calculate the pixel-millimeter-ratio. First, a ROI is detected and cropped
based on regression tree voting. Second, an algorithm is employed in ROI to
detect the corner points of the scale and rotate the scale to perfectly
vertical direction. Finally, a pixel tracing algorithm is employed to locate
the first and the last scale mark in order to calculate the pixel length of the
calibration. A novel method is proposed to adaptively assign the size and
orientation of the image patches described by the SIFT vectors to ensure
invariance of scale and rotation of images. The algorithm is robust to
interference including tags, stickers and stain. A dataset consisting 163
cephalograms is tested and the algorithm performs a 100% Success Detection Rate
within the precision range of 1.0mm.",2019-12-07T17:47:01Z,http://arxiv.org/abs/1912.03537v1,orthodontics
"TSGCNet: Discriminative Geometric Feature Learning with Two-Stream
  GraphConvolutional Network for 3D Dental Model Segmentation","Lingming Zhang, Yue Zhao, Deyu Meng, Zhiming Cui, Chenqiang Gao, Xinbo Gao, Chunfeng Lian, Dinggang Shen","The ability to segment teeth precisely from digitized 3D dental models is an
essential task in computer-aided orthodontic surgical planning. To date, deep
learning based methods have been popularly used to handle this task.
State-of-the-art methods directly concatenate the raw attributes of 3D inputs,
namely coordinates and normal vectors of mesh cells, to train a single-stream
network for fully-automated tooth segmentation. This, however, has the drawback
of ignoring the different geometric meanings provided by those raw attributes.
This issue might possibly confuse the network in learning discriminative
geometric features and result in many isolated false predictions on the dental
model. Against this issue, we propose a two-stream graph convolutional network
(TSGCNet) to learn multi-view geometric information from different geometric
attributes. Our TSGCNet adopts two graph-learning streams, designed in an
input-aware fashion, to extract more discriminative high-level geometric
representations from coordinates and normal vectors, respectively. These
feature representations learned from the designed two different streams are
further fused to integrate the multi-view complementary information for the
cell-wise dense prediction task. We evaluate our proposed TSGCNet on a
real-patient dataset of dental models acquired by 3D intraoral scanners, and
experimental results demonstrate that our method significantly outperforms
state-of-the-art methods for 3D shape segmentation.",2020-12-26T08:02:56Z,http://arxiv.org/abs/2012.13697v1,orthodontics
"Tooth Instance Segmentation from Cone-Beam CT Images through Point-based
  Detection and Gaussian Disentanglement","Jusang Lee, Minyoung Chung, Minkyung Lee, Yeong-Gil Shin","Individual tooth segmentation and identification from cone-beam computed
tomography images are preoperative prerequisites for orthodontic treatments.
Instance segmentation methods using convolutional neural networks have
demonstrated ground-breaking results on individual tooth segmentation tasks,
and are used in various medical imaging applications. While point-based
detection networks achieve superior results on dental images, it is still a
challenging task to distinguish adjacent teeth because of their similar
topologies and proximate nature. In this study, we propose a point-based tooth
localization network that effectively disentangles each individual tooth based
on a Gaussian disentanglement objective function. The proposed network first
performs heatmap regression accompanied by box regression for all the
anatomical teeth. A novel Gaussian disentanglement penalty is employed by
minimizing the sum of the pixel-wise multiplication of the heatmaps for all
adjacent teeth pairs. Subsequently, individual tooth segmentation is performed
by converting a pixel-wise labeling task to a distance map regression task to
minimize false positives in adjacent regions of the teeth. Experimental results
demonstrate that the proposed algorithm outperforms state-of-the-art approaches
by increasing the average precision of detection by 9.1%, which results in a
high performance in terms of individual tooth segmentation. The primary
significance of the proposed method is two-fold: 1) the introduction of a
point-based tooth detection framework that does not require additional
classification and 2) the design of a novel loss function that effectively
separates Gaussian distributions based on heatmap responses in the point-based
detection framework.",2021-02-02T05:15:50Z,http://arxiv.org/abs/2102.01315v1,orthodontics
DArch: Dental Arch Prior-assisted 3D Tooth Instance Segmentation,"Liangdong Qiu, Chongjie Ye, Pei Chen, Yunbi Liu, Xiaoguang Han, Shuguang Cui","Automatic tooth instance segmentation on 3D dental models is a fundamental
task for computer-aided orthodontic treatments. Existing learning-based methods
rely heavily on expensive point-wise annotations. To alleviate this problem, we
are the first to explore a low-cost annotation way for 3D tooth instance
segmentation, i.e., labeling all tooth centroids and only a few teeth for each
dental model. Regarding the challenge when only weak annotation is provided, we
present a dental arch prior-assisted 3D tooth segmentation method, namely
DArch. Our DArch consists of two stages, including tooth centroid detection and
tooth instance segmentation. Accurately detecting the tooth centroids can help
locate the individual tooth, thus benefiting the segmentation. Thus, our DArch
proposes to leverage the dental arch prior to assist the detection.
Specifically, we firstly propose a coarse-to-fine method to estimate the dental
arch, in which the dental arch is initially generated by Bezier curve
regression, and then a graph-based convolutional network (GCN) is trained to
refine it. With the estimated dental arch, we then propose a novel Arch-aware
Point Sampling (APS) method to assist the tooth centroid proposal generation.
Meantime, a segmentor is independently trained using a patch-based training
strategy, aiming to segment a tooth instance from a 3D patch centered at the
tooth centroid. Experimental results on $4,773$ dental models have shown our
DArch can accurately segment each tooth of a dental model, and its performance
is superior to the state-of-the-art methods.",2022-04-25T18:30:01Z,http://arxiv.org/abs/2204.11911v1,orthodontics
"Automatic Tooth Segmentation from 3D Dental Model using Deep Learning: A
  Quantitative Analysis of what can be learnt from a Single 3D Dental Model","Ananya Jana, Hrebesh Molly Subhash, Dimitris Metaxas","3D tooth segmentation is an important task for digital orthodontics. Several
Deep Learning methods have been proposed for automatic tooth segmentation from
3D dental models or intraoral scans. These methods require annotated 3D
intraoral scans. Manually annotating 3D intraoral scans is a laborious task.
One approach is to devise self-supervision methods to reduce the manual
labeling effort. Compared to other types of point cloud data like scene point
cloud or shape point cloud data, 3D tooth point cloud data has a very regular
structure and a strong shape prior. We look at how much representative
information can be learnt from a single 3D intraoral scan. We evaluate this
quantitatively with the help of ten different methods of which six are generic
point cloud segmentation methods whereas the other four are tooth segmentation
specific methods. Surprisingly, we find that with a single 3D intraoral scan
training, the Dice score can be as high as 0.86 whereas the full training set
gives Dice score of 0.94. We conclude that the segmentation methods can learn a
great deal of information from a single 3D tooth point cloud scan under
suitable conditions e.g. data augmentation. We are the first to quantitatively
evaluate and demonstrate the representation learning capability of Deep
Learning methods from a single 3D intraoral scan. This can enable building
self-supervision methods for tooth segmentation under extreme data limitation
scenario by leveraging the available data to the fullest possible extent.",2022-09-16T19:03:10Z,http://arxiv.org/abs/2209.08132v1,orthodontics
Teeth3DS+: An Extended Benchmark for Intraoral 3D Scans Analysis,"Achraf Ben-Hamadou, Nour Neifar, Ahmed Rekik, Oussama Smaoui, Firas Bouzguenda, Sergi Pujades, Edmond Boyer, Edouard Ladroit","Intraoral 3D scans analysis is a fundamental aspect of Computer-Aided
Dentistry (CAD) systems, playing a crucial role in various dental applications,
including teeth segmentation, detection, labeling, and dental landmark
identification. Accurate analysis of 3D dental scans is essential for
orthodontic and prosthetic treatment planning, as it enables automated
processing and reduces the need for manual adjustments by dental professionals.
However, developing robust automated tools for these tasks remains a
significant challenge due to the limited availability of high-quality public
datasets and benchmarks. This article introduces Teeth3DS+, the first
comprehensive public benchmark designed to advance the field of intraoral 3D
scan analysis. Developed as part of the 3DTeethSeg 2022 and 3DTeethLand 2024
MICCAI challenges, Teeth3DS+ aims to drive research in teeth identification,
segmentation, labeling, 3D modeling, and dental landmarks identification. The
dataset includes at least 1,800 intraoral scans (containing 23,999 annotated
teeth) collected from 900 patients, covering both upper and lower jaws
separately. All data have been acquired and validated by experienced
orthodontists and dental surgeons with over five years of expertise. Detailed
instructions for accessing the dataset are available at
https://crns-smartvision.github.io/teeth3ds",2022-10-12T11:18:35Z,http://arxiv.org/abs/2210.06094v2,orthodontics
"ToothInpaintor: Tooth Inpainting from Partial 3D Dental Model and 2D
  Panoramic Image","Yuezhi Yang, Zhiming Cui, Changjian Li, Wenping Wang","In orthodontic treatment, a full tooth model consisting of both the crown and
root is indispensable in making the treatment plan. However, acquiring tooth
root information to obtain the full tooth model from CBCT images is sometimes
restricted due to the massive radiation of CBCT scanning. Thus, reconstructing
the full tooth shape from the ready-to-use input, e.g., the partial intra-oral
scan and the 2D panoramic image, is an applicable and valuable solution. In
this paper, we propose a neural network, called ToothInpaintor, that takes as
input a partial 3D dental model and a 2D panoramic image and reconstructs the
full tooth model with high-quality root(s). Technically, we utilize the
implicit representation for both the 3D and 2D inputs, and learn a latent space
of the full tooth shapes. At test time, given an input, we successfully project
it to the learned latent space via neural optimization to obtain the full tooth
model conditioned on the input. To help find the robust projection, a novel
adversarial learning module is exploited in our pipeline. We extensively
evaluate our method on a dataset collected from real-world clinics. The
evaluation, comparison, and comprehensive ablation studies demonstrate that our
approach produces accurate complete tooth models robustly and outperforms the
state-of-the-art methods.",2022-11-25T18:15:22Z,http://arxiv.org/abs/2211.15502v1,orthodontics
"Revisiting Cephalometric Landmark Detection from the view of Human Pose
  Estimation with Lightweight Super-Resolution Head","Qian Wu, Si Yong Yeo, Yufei Chen, Jun Liu","Accurate localization of cephalometric landmarks holds great importance in
the fields of orthodontics and orthognathics due to its potential for
automating key point labeling. In the context of landmark detection,
particularly in cephalometrics, it has been observed that existing methods
often lack standardized pipelines and well-designed bias reduction processes,
which significantly impact their performance. In this paper, we revisit a
related task, human pose estimation (HPE), which shares numerous similarities
with cephalometric landmark detection (CLD), and emphasize the potential for
transferring techniques from the former field to benefit the latter. Motivated
by this insight, we have developed a robust and adaptable benchmark based on
the well-established HPE codebase known as MMPose. This benchmark can serve as
a dependable baseline for achieving exceptional CLD performance. Furthermore,
we introduce an upscaling design within the framework to further enhance
performance. This enhancement involves the incorporation of a lightweight and
efficient super-resolution module, which generates heatmap predictions on
high-resolution features and leads to further performance refinement,
benefiting from its ability to reduce quantization bias. In the MICCAI
CLDetection2023 challenge, our method achieves 1st place ranking on three
metrics and 3rd place on the remaining one. The code for our method is
available at https://github.com/5k5000/CLdetection2023.",2023-09-29T11:15:39Z,http://arxiv.org/abs/2309.17143v1,orthodontics
"Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic
  Treatment based on Anthropic Prior Knowledge","Bo Zou, Shaofeng Wang, Hao Liu, Gaoyue Sun, Yajie Wang, FeiFei Zuo, Chengbin Quan, Youjian Zhao","Teeth localization, segmentation, and labeling in 2D images have great
potential in modern dentistry to enhance dental diagnostics, treatment
planning, and population-based studies on oral health. However, general
instance segmentation frameworks are incompetent due to 1) the subtle
differences between some teeth' shapes (e.g., maxillary first premolar and
second premolar), 2) the teeth's position and shape variation across subjects,
and 3) the presence of abnormalities in the dentition (e.g., caries and
edentulism). To address these problems, we propose a ViT-based framework named
TeethSEG, which consists of stacked Multi-Scale Aggregation (MSA) blocks and an
Anthropic Prior Knowledge (APK) layer. Specifically, to compose the two
modules, we design 1) a unique permutation-based upscaler to ensure high
efficiency while establishing clear segmentation boundaries with 2) multi-head
self/cross-gating layers to emphasize particular semantics meanwhile
maintaining the divergence between token embeddings. Besides, we collect 3) the
first open-sourced intraoral image dataset IO150K, which comprises over 150k
intraoral photos, and all photos are annotated by orthodontists using a
human-machine hybrid algorithm. Experiments on IO150K demonstrate that our
TeethSEG outperforms the state-of-the-art segmentation models on dental image
segmentation.",2024-04-01T09:34:51Z,http://arxiv.org/abs/2404.01013v1,orthodontics
"T-Mamba: A unified framework with Long-Range Dependency in dual-domain
  for 2D & 3D Tooth Segmentation","Jing Hao, Yonghui Zhu, Lei He, Moyun Liu, James Kit Hon Tsoi, Kuo Feng Hung","Tooth segmentation is a pivotal step in modern digital dentistry, essential
for applications across orthodontic diagnosis and treatment planning. Despite
its importance, this process is fraught with challenges due to the high noise
and low contrast inherent in 2D and 3D tooth data. Both Convolutional Neural
Networks (CNNs) and Transformers has shown promise in medical image
segmentation, yet each method has limitations in handling long-range
dependencies and computational complexity. To address this issue, this paper
introduces T-Mamba, integrating frequency-based features and shared
bi-positional encoding into vision mamba to address limitations in efficient
global feature modeling. Besides, we design a gate selection unit to integrate
two features in spatial domain and one feature in frequency domain adaptively.
T-Mamba is the first work to introduce frequency-based features into vision
mamba, and its flexibility allows it to process both 2D and 3D tooth data
without the need for separate modules. Also, the TED3, a large-scale public
tooth 2D dental X-ray dataset, has been presented in this paper. Extensive
experiments demonstrate that T-Mamba achieves new SOTA results on a public
tooth CBCT dataset and outperforms previous SOTA methods on TED3 dataset. The
code and models are publicly available at: https://github.com/isbrycee/T-Mamba.",2024-04-01T11:57:40Z,http://arxiv.org/abs/2404.01065v2,orthodontics
Cephalometric Landmark Detection across Ages with Prototypical Network,"Han Wu, Chong Wang, Lanzhuju Mei, Tong Yang, Min Zhu, Dingggang Shen, Zhiming Cui","Automated cephalometric landmark detection is crucial in real-world
orthodontic diagnosis. Current studies mainly focus on only adult subjects,
neglecting the clinically crucial scenario presented by adolescents whose
landmarks often exhibit significantly different appearances compared to adults.
Hence, an open question arises about how to develop a unified and effective
detection algorithm across various age groups, including adolescents and
adults. In this paper, we propose CeLDA, the first work for Cephalometric
Landmark Detection across Ages. Our method leverages a prototypical network for
landmark detection by comparing image features with landmark prototypes. To
tackle the appearance discrepancy of landmarks between age groups, we design
new strategies for CeLDA to improve prototype alignment and obtain a holistic
estimation of landmark prototypes from a large set of training images.
Moreover, a novel prototype relation mining paradigm is introduced to exploit
the anatomical relations between the landmark prototypes. Extensive experiments
validate the superiority of CeLDA in detecting cephalometric landmarks on both
adult and adolescent subjects. To our knowledge, this is the first effort
toward developing a unified solution and dataset for cephalometric landmark
detection across age groups. Our code and dataset will be made public on
https://github.com/ShanghaiTech-IMPACT/Cephalometric-Landmark-Detection-across-Ages-with-Prototypical-Network",2024-06-18T13:04:52Z,http://arxiv.org/abs/2406.12577v1,orthodontics
"When 3D Partial Points Meets SAM: Tooth Point Cloud Segmentation with
  Sparse Labels","Yifan Liu, Wuyang Li, Cheng Wang, Hui Chen, Yixuan Yuan","Tooth point cloud segmentation is a fundamental task in many orthodontic
applications. Current research mainly focuses on fully supervised learning
which demands expensive and tedious manual point-wise annotation. Although
recent weakly-supervised alternatives are proposed to use weak labels for 3D
segmentation and achieve promising results, they tend to fail when the labels
are extremely sparse. Inspired by the powerful promptable segmentation
capability of the Segment Anything Model (SAM), we propose a framework named
SAMTooth that leverages such capacity to complement the extremely sparse
supervision. To automatically generate appropriate point prompts for SAM, we
propose a novel Confidence-aware Prompt Generation strategy, where coarse
category predictions are aggregated with confidence-aware filtering.
Furthermore, to fully exploit the structural and shape clues in SAM's outputs
for assisting the 3D feature learning, we advance a Mask-guided Representation
Learning that re-projects the generated tooth masks of SAM into 3D space and
constrains these points of different teeth to possess distinguished
representations. To demonstrate the effectiveness of the framework, we conduct
experiments on the public dataset and surprisingly find with only 0.1\%
annotations (one point per tooth), our method can surpass recent weakly
supervised methods by a large margin, and the performance is even comparable to
the recent fully-supervised methods, showcasing the significant potential of
applying SAM to 3D perception tasks with sparse labels. Code is available at
https://github.com/CUHK-AIM-Group/SAMTooth.",2024-09-03T08:14:56Z,http://arxiv.org/abs/2409.01691v1,orthodontics
"Differentiable Collision-Supervised Tooth Arrangement Network with a
  Decoupling Perspective","Zhihui He, Chengyuan Wang, Shidong Yang, Li Chen, Yanheng Zhou, Shuo Wang","Tooth arrangement is an essential step in the digital orthodontic planning
process. Existing learning-based methods use hidden teeth features to directly
regress teeth motions, which couples target pose perception and motion
regression. It could lead to poor perceptions of three-dimensional
transformation. They also ignore the possible overlaps or gaps between teeth of
predicted dentition, which is generally unacceptable. Therefore, we propose
DTAN, a differentiable collision-supervised tooth arrangement network,
decoupling predicting tasks and feature modeling. DTAN decouples the tooth
arrangement task by first predicting the hidden features of the final teeth
poses and then using them to assist in regressing the motions between the
beginning and target teeth. To learn the hidden features better, DTAN also
decouples the teeth-hidden features into geometric and positional features,
which are further supervised by feature consistency constraints. Furthermore,
we propose a novel differentiable collision loss function for point cloud data
to constrain the related gestures between teeth, which can be easily extended
to other 3D point cloud tasks. We propose an arch-width guided tooth
arrangement network, named C-DTAN, to make the results controllable. We
construct three different tooth arrangement datasets and achieve drastically
improved performance on accuracy and speed compared with existing methods.",2024-09-18T12:52:54Z,http://arxiv.org/abs/2409.11937v1,orthodontics
