from datasets import load_dataset
from transformers import MT5Tokenizer, MT5ForConditionalGeneration
from tqdm import tqdm
import pandas as pd
import torch
import os

def augment_and_save_paraphrases(
    dataset_name: str,
    split: str,
    checkpoint: str,
    output_file: str,
    num_return_sequences: int = 10,
    max_length: int = 512,
    device: str = None
):
    """
    T·∫°o d·ªØ li·ªáu paraphrase t·ª´ m·ªôt dataset v√† l∆∞u v√†o file Excel.

    Args:
        dataset_name (str): T√™n dataset tr√™n Huggingface datasets.
        split (str): T√™n split c·ªßa dataset (vd: 'train', 'test').
        checkpoint (str): T√™n checkpoint model paraphrase huggingface.
        output_file (str): ƒê∆∞·ªùng d·∫´n file Excel ƒë·ªÉ l∆∞u d·ªØ li·ªáu.
        num_return_sequences (int, optional): S·ªë c√¢u paraphrase t·∫°o ra cho m·ªói c√¢u g·ªëc. M·∫∑c ƒë·ªãnh 10.
        max_length (int, optional): ƒê·ªô d√†i t·ªëi ƒëa c√¢u ƒë·∫ßu v√†o v√† ƒë·∫ßu ra. M·∫∑c ƒë·ªãnh 512.
        device (str, optional): Thi·∫øt b·ªã ch·∫°y m√¥ h√¨nh (vd: 'cuda', 'cpu'). M·∫∑c ƒë·ªãnh t·ª± detect.
    """
    # Setup device
    device = device or ("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üíª ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: {device}")

    # Load model v√† tokenizer
    tokenizer = MT5Tokenizer.from_pretrained(checkpoint)
    model = MT5ForConditionalGeneration.from_pretrained(checkpoint).to(device)

    # Load dataset
    dataset = load_dataset(dataset_name, split=split)

    # Ki·ªÉm tra v√† t·∫°o file Excel n·∫øu ch∆∞a c√≥
    if not os.path.exists(output_file):
        df_empty = pd.DataFrame(columns=["C√¢u h·ªèi", "CoT_Goal", "CoT_Reasoning", "CoT_Justification", "C√¢u tr·∫£ l·ªùi"])
        df_empty.to_excel(output_file, index=False)

    def paraphrase(text, num_return_sequences=num_return_sequences):
        inputs = tokenizer(text, padding='longest', max_length=max_length, truncation=True, return_tensors='pt')
        inputs = {key: val.to(device) for key, val in inputs.items()}
        outputs = model.generate(
            inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            max_length=max_length,
            num_return_sequences=num_return_sequences,
            do_sample=True,
            top_p=0.95
        )
        return [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]

    # M·ªü Excel writer m·ªôt l·∫ßn v√† append d·ªØ li·ªáu theo batch (ƒë·ªÉ t·ªëi ∆∞u h∆°n)
    from openpyxl import load_workbook

    # ƒê·ªçc s·ªë d√≤ng hi·ªán t·∫°i ƒë·ªÉ append ƒë√∫ng v·ªã tr√≠
    if os.path.exists(output_file):
        wb = load_workbook(output_file)
        ws = wb.active
        startrow = ws.max_row
        wb.close()
    else:
        startrow = 1

    for example in tqdm(dataset, desc="ƒêang t·∫°o v√† l∆∞u d·ªØ li·ªáu paraphrase"):
        question = example["C√¢u h·ªèi"]
        try:
            paraphrases = paraphrase(question)
        except Exception as e:
            print(f"L·ªói paraphrase c√¢u: {question}\nL·ªói: {e}")
            paraphrases = [question]

        rows = []
        for pq in paraphrases:
            rows.append({
                "C√¢u h·ªèi": pq,
                "CoT_Goal": example["CoT_Goal"],
                "CoT_Reasoning": example["CoT_Reasoning"],
                "CoT_Justification": example["CoT_Justification"],
                "C√¢u tr·∫£ l·ªùi": example["C√¢u tr·∫£ l·ªùi"]
            })

        df_batch = pd.DataFrame(rows)

        # Append v√†o file Excel (mode a, startrow t∆∞∆°ng ·ª©ng)
        with pd.ExcelWriter(output_file, mode='a', if_sheet_exists='overlay', engine='openpyxl') as writer:
            writer.sheets = {ws.title: ws for ws in writer.book.worksheets}
            df_batch.to_excel(writer, header=False, index=False, startrow=writer.sheets["Sheet1"].max_row)

    print("‚úÖ ƒê√£ l∆∞u to√†n b·ªô d·ªØ li·ªáu paraphrase v√†o file Excel.")

# V√≠ d·ª• g·ªçi h√†m:
if __name__ == "__main__":
    augment_and_save_paraphrases(
        dataset_name="NV9523/DentalGPT_SFT",
        split="train",
        checkpoint="chieunq/vietnamese-sentence-paraphase",
        output_file="DentalGPT_SFT_augmented.xlsx",
        num_return_sequences=10,
        max_length=512
    )
